<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-06-30 zo 11:56 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Notes deel 2</title>
<meta name="author" content="Martijn Voordouw" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/bigblow_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/bigblow_theme/css/bigblow.css"/>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/bigblow_theme/css/hideshow.css"/>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/bigblow_theme/js/jquery-1.11.0.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/bigblow_theme/js/jquery-ui-1.10.2.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/bigblow_theme/js/jquery.localscroll-min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/bigblow_theme/js/jquery.scrollTo-1.4.3.1-min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/bigblow_theme/js/jquery.zclip.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/bigblow_theme/js/bigblow.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/bigblow_theme/js/hideshow.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Notes deel 2</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgc6e5f0d">1. Divide and Conquer</a>
<ul>
<li><a href="#orgf927dc1">1.1. Divide and Conquer : in het algemeen</a></li>
<li><a href="#org49e0e45">1.2. Correctheid: inductie</a></li>
<li><a href="#org16ebef5">1.3. MergeSort</a>
<ul>
<li><a href="#orgb06facd">1.3.1. Correctheid Mergesort</a></li>
<li><a href="#orgc1e77da">1.3.2. Looptijd</a></li>
</ul>
</li>
<li><a href="#org368b706">1.4. Oplossen recurrente betrekking</a>
<ul>
<li><a href="#org3f34ece">1.4.1. Subsitutie</a></li>
<li><a href="#org0bd94ac">1.4.2. Recursieboom</a></li>
<li><a href="#orga1230c2">1.4.3. master theorem</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org15820b3">2. Recursief programmeren</a>
<ul>
<li><a href="#org1ffeea8">2.1. Gepast betalen</a></li>
<li><a href="#orgc177f72">2.2. optimaliteitsprincipe</a></li>
<li><a href="#orgbdc34d4">2.3. Samenvatting</a></li>
</ul>
</li>
<li><a href="#orgcc356a9">3. Dynamisch Programmeren</a>
<ul>
<li><a href="#org0b7e616">3.1. Driehoek van Pascal DP</a></li>
<li><a href="#org33d062b">3.2. Klassiek DP</a>
<ul>
<li><a href="#orged16b8d">3.2.1. Ontwerp</a></li>
<li><a href="#org33a52e5">3.2.2. Constructieversies</a></li>
<li><a href="#orgb87a556">3.2.3. Voorbeeld: gepast betalen:</a></li>
</ul>
</li>
<li><a href="#orgda768dd">3.3. Keuzes/deelproblemen identificeren</a></li>
<li><a href="#org1d33ad1">3.4. Traveling Salesman problem</a>
<ul>
<li><a href="#orgbb84f22">3.4.1. Complexiteit</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org6bde84c">4. Greedy algorithms</a>
<ul>
<li><a href="#orgf3692c8">4.1. Fractional Knapsack problem, Interval Scheduling en Huffman&rsquo;s codes</a></li>
</ul>
</li>
<li><a href="#org8b96435">5. Graphs</a>
<ul>
<li><a href="#org0d66541">5.1. Graph representation</a></li>
<li><a href="#org202790e">5.2. Adjacency list</a></li>
<li><a href="#org3db8305">5.3. Adjacency Matrix</a></li>
<li><a href="#orge694447">5.4. Adjacency List and Adjacency Matrix</a></li>
<li><a href="#orga5c819b">5.5. Depth-First Search</a>
<ul>
<li><a href="#orge8a852d">5.5.1. Parenthesis Theorem</a></li>
<li><a href="#org3f6fdbd">5.5.2. Edges Classification</a></li>
<li><a href="#org86b5adf">5.5.3. White-Path Theorem</a></li>
</ul>
</li>
<li><a href="#orgabf6750">5.6. Directed Acyclic Graph</a></li>
<li><a href="#org817f940">5.7. Strongly connected component</a></li>
</ul>
</li>
<li><a href="#org070655d">6. Single source shortest path</a>
<ul>
<li><a href="#orge47116b">6.1. Breadth-First Search: unweighted graph or graph with uniform weight</a></li>
<li><a href="#orge03ba8f">6.2. Tense edges and relaxation</a></li>
<li><a href="#org42e72c7">6.3. Weighted DAG single source shortest path</a></li>
<li><a href="#org7ff856c">6.4. Dijkstras algorithm: weigthed graph with non-negagive weight</a></li>
<li><a href="#org3e4dd5b">6.5. Bellman-Ford: weigthed graph without negative cycle</a></li>
</ul>
</li>
<li><a href="#org2333217">7. All pair shortest paths</a>
<ul>
<li><a href="#orgf43e525">7.1. Lots of single sources</a></li>
<li><a href="#orgcee580d">7.2. DP by length</a></li>
<li><a href="#org728e01c">7.3. Floyd-Warhall algorithm</a></li>
<li><a href="#org1e52358">7.4. Johsons algorithm</a></li>
</ul>
</li>
<li><a href="#orgc2984f7">8. Matchings</a>
<ul>
<li><a href="#orgabb7b28">8.1. Matchings</a></li>
<li><a href="#orgdc76a21">8.2. Matchings in bipartite graphs</a></li>
<li><a href="#org13912af">8.3. Matchings of different types of graphs</a></li>
<li><a href="#orgf0f97aa">8.4. Stable matching / stable-marriage problem</a></li>
</ul>
</li>
<li><a href="#org8d4e057">9. Flow and cuts</a>
<ul>
<li><a href="#org708bd59">9.1. Flow</a></li>
<li><a href="#org12d85aa">9.2. Bipartite matching as flow</a></li>
<li><a href="#org02e3bad">9.3. Generalized matching as flow</a></li>
<li><a href="#orgda691ef">9.4. The Ford-Fulkerson Algorithm</a></li>
<li><a href="#org1e3ea2e">9.5. Cuts</a>
<ul>
<li><a href="#org6f448cf">9.5.1. Finding a mimimum cut</a></li>
</ul>
</li>
<li><a href="#orga899c78">9.6. Edmonds-Karp Algorithm</a></li>
<li><a href="#org7544539">9.7. Other algorithms</a></li>
</ul>
</li>
<li><a href="#org681704b">10. Amortized analysis</a>
<ul>
<li><a href="#org2af4abf">10.1. Super stack</a></li>
<li><a href="#org76f9865">10.2. Aggregate method</a>
<ul>
<li><a href="#org25ec977">10.2.1. Super stack example</a></li>
</ul>
</li>
<li><a href="#orgc3267ba">10.3. Accounting method</a>
<ul>
<li><a href="#orgc126b19">10.3.1. Super stack example</a></li>
</ul>
</li>
<li><a href="#org5b66b54">10.4. Potential function</a></li>
<li><a href="#org9ab8fdd">10.5. Fibonacci heaps</a>
<ul>
<li><a href="#org8af62e8">10.5.1. binary heap</a></li>
<li><a href="#orgddd6be5">10.5.2. Fibonacci Heaps Structure</a></li>
<li><a href="#org2785a9c">10.5.3. Fibonacci heap operations</a></li>
<li><a href="#orgb72db7a">10.5.4. Amortized analysis of Fibonacci heaps</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgb21b9b3">11. Minimum spanning trees and Union find</a>
<ul>
<li><a href="#org131f47d">11.1. Generic MST algorithm</a></li>
<li><a href="#orgf5a49f6">11.2. Light Edges</a></li>
<li><a href="#orgb3a7303">11.3. Boruvka&rsquo;s algorithm</a></li>
<li><a href="#org5d9c1f6">11.4. Prim&rsquo;s algorithm</a></li>
<li><a href="#org44a892a">11.5. Disjoint Set Union-Find</a>
<ul>
<li><a href="#orgb60aa50">11.5.1. Linked lists</a></li>
<li><a href="#orgc351cc6">11.5.2. Forest</a></li>
</ul>
</li>
<li><a href="#orgc7fd750">11.6. Kruskal&rsquo;s algorithm</a></li>
<li><a href="#org0ddce7d">11.7. Graphs with repeated weights</a></li>
</ul>
</li>
<li><a href="#org1d57d33">12. NP-completeness</a>
<ul>
<li><a href="#orgf85c468">12.1. P and NP</a>
<ul>
<li><a href="#orge4d1aa1">12.1.1. The class P</a></li>
<li><a href="#orgf5d55e5">12.1.2. The class NP</a></li>
</ul>
</li>
<li><a href="#orgae1e95d">12.2. Polynomial-time reduction and NP-hardness</a></li>
<li><a href="#orgadb9354">12.3. NP-Completeness</a></li>
</ul>
</li>
<li><a href="#org0fe8dbe">13. Approximation Algorithms</a>
<ul>
<li><a href="#org214b5d1">13.1. Minimum vertex cover approximation algorithm</a></li>
<li><a href="#org2a36220">13.2. Knapsack approximation algorithm</a></li>
<li><a href="#orgf8419d6">13.3. Improving an approximation algorithm</a></li>
</ul>
</li>
<li><a href="#org796ec37">14. String Matching</a>
<ul>
<li><a href="#orgd814cbc">14.1. Kansrekening</a></li>
<li><a href="#orgecaebc5">14.2. Naief algoritme</a></li>
<li><a href="#org6c798a4">14.3. Rabin-Karp</a></li>
<li><a href="#org3f290b9">14.4. Eindige automaat</a></li>
</ul>
</li>
<li><a href="#org8cb2203">15. Gerandomiseerde algoritmes</a>
<ul>
<li><a href="#org9643cb6">15.1. <span class="todo TODO">TODO</span> Minimum cut probleem met gerandomiseerd algoritme</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-orgc6e5f0d" class="outline-2">
<h2 id="orgc6e5f0d"><span class="section-number-2">1.</span> Divide and Conquer</h2>
<div class="outline-text-2" id="text-1">
<p>
grote O: \(f(n)=O(g(n))\) als er een constante c bestaat zdd voor iedere \(n\ge n_0\) geldt dat \(f(n)\le c*g(n)\)
</p>

<ul class="org-ul">
<li>\(f(n)=O(g(n))\): f(n) is asymptotisch hoogstens g(n)</li>
<li>\(f(n)=\Omega(g(n))\): f(n) is asymptotisch minstens g(n)</li>
<li>\(f(n)=\Theta(g(n))\): f(n) is asymptotisch gelijk aan g(n)</li>
<li>\(f(n)=o(g(n))\): f(n) is asymp. &rsquo;strict kleiner&rsquo; dan g(n)</li>
<li>\(f(n)=\omega(g(n))\): f(n) is asymp. &rsquo;strict groter&rsquo; dan g(n)</li>
</ul>
</div>
<div id="outline-container-orgf927dc1" class="outline-3">
<h3 id="orgf927dc1"><span class="section-number-3">1.1.</span> Divide and Conquer : in het algemeen</h3>
<div class="outline-text-3" id="text-1-1">
<ol class="org-ol">
<li>Divide: splits in deelproblemen</li>
<li>Conquer: los deelproblemen recursief op</li>
<li>Combine: voeg deeloplossingen samen tot oplossing hele probleem</li>
<li>Basisgeval: niet vergeten</li>
</ol>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #bb99ee;">if</span> <span style="color: #ee8899;">input</span> <span style="color: #bb99ee;">is</span> <span style="color: #99dd99;">'klein'</span>
then los direct op (basisgeval)
<span style="color: #bb99ee;">else</span> splits <span style="color: #bb99ee;">in</span> deelproblemen
    los deelproblemen recursief op
    oplossingen deelproblemn samenvoegen
</pre>
</div>

<ul class="org-ul">
<li>Doe geen overbodig werk
<ul class="org-ul">
<li>Bijv.: iedere keer sorteren, arrays kopi√´ren</li>
</ul></li>
<li>Denk goed na over je combine-stap
<ul class="org-ul">
<li>Gebruik hulpwaarden!</li>
</ul></li>
<li>Soms kan het handig zijn om de invoer in meer dan twee stukken te splitsen
<ul class="org-ul">
<li>Zie bijvoorbeeld Selection-algoritme (boek 9.3)</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org49e0e45" class="outline-3">
<h3 id="org49e0e45"><span class="section-number-3">1.2.</span> Correctheid: inductie</h3>
<div class="outline-text-3" id="text-1-2">
<ul class="org-ul">
<li>Bewijs dat basisgeval correct is</li>
<li>Inductiehypothese: algoritme werkt voor alle kleinere invoeren</li>
<li>Inductiestap:
<ul class="org-ul">
<li>Deelproblemen hebben kleinere invoeren en worden dus correct opgelost (IH)</li>
<li>Oplossingen van deelproblemen worden correct samengevoegd</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org16ebef5" class="outline-3">
<h3 id="org16ebef5"><span class="section-number-3">1.3.</span> MergeSort</h3>
<div class="outline-text-3" id="text-1-3">
<p>
Sorteer array van getallen
</p>

<ol class="org-ol">
<li>Divide: splits array in twee helften</li>
<li>Conquer: sorteer helften</li>
<li>Combine: voeg gesorteerde lijsten samen tot √©√©n gesorteerde lijst
<ul class="org-ul">
<li>Pak telkens kleinste element uit twee lijsten</li>
</ul></li>
<li>Basisgeval: array heeft grootte 1</li>
</ol>

<div class="org-src-container">
<pre class="src src-python">MergeSort(<span style="color: #ee8899;">int</span>[] X, <span style="color: #ee8899;">int</span> a, <span style="color: #ee8899;">int</span> b)
    <span style="color: #bb99ee;">if</span> b<span style="color: #88ccdd;">-</span>a <span style="color: #88ccdd;">==</span> <span style="color: #eeaa77;">1</span> then <span style="color: #bb99ee;">return</span>
    MergeSort(X, a, (a<span style="color: #88ccdd;">+</span>b)<span style="color: #88ccdd;">/</span><span style="color: #eeaa77;">2</span>)
    MergeSort(X, (a<span style="color: #88ccdd;">+</span>b)<span style="color: #88ccdd;">/</span><span style="color: #eeaa77;">2</span>, b)
    Merge(X, a, (a<span style="color: #88ccdd;">+</span>b)<span style="color: #88ccdd;">/</span><span style="color: #eeaa77;">2</span>, b)
</pre>
</div>
</div>
<div id="outline-container-orgb06facd" class="outline-4">
<h4 id="orgb06facd"><span class="section-number-4">1.3.1.</span> Correctheid Mergesort</h4>
<div class="outline-text-4" id="text-1-3-1">
<ul class="org-ul">
<li>Gebruik inductie!</li>
<li>Basisgeval: lijst van 1 element altijd gesorteerd</li>
<li>Inductiehypothese: Algoritme sorteert correct voor alle arrays met minder dan n elementen</li>

<li>Inductiehypothese: Algoritme sorteert correct voor alle arrays met minder dan n elementen</li>
<li>Inductiestap: Invoer is een array met n elementen
<ul class="org-ul">
<li>Twee helften worden correct gesorteerd (IH)</li>
<li>Merge werkt correct (Apart bewijs)</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgc1e77da" class="outline-4">
<h4 id="orgc1e77da"><span class="section-number-4">1.3.2.</span> Looptijd</h4>
<div class="outline-text-4" id="text-1-3-2">
<ul class="org-ul">
<li>MergeSort(int[] X, int a, int b)  O(1)</li>
<li>if b-a == 1 then return           T(n)</li>
<li>MergeSort(X, a, (a+b)/2)          T(n/2)</li>
<li>MergeSort(X, (a+b)/2, b)          T(n/2)</li>
<li>Merge(X, a, (a+b)/2, b)           O(n)</li>
</ul>

<p>
<b>Recurrente betrekking:</b> T(n) = 2T(n/2) + O(n)
</p>
</div>
</div>
</div>
<div id="outline-container-org368b706" class="outline-3">
<h3 id="org368b706"><span class="section-number-3">1.4.</span> Oplossen recurrente betrekking</h3>
<div class="outline-text-3" id="text-1-4">
</div>
<div id="outline-container-org3f34ece" class="outline-4">
<h4 id="org3f34ece"><span class="section-number-4">1.4.1.</span> Subsitutie</h4>
<div class="outline-text-4" id="text-1-4-1">
<ul class="org-ul">
<li>Inductiebewijs!</li>
<li>Gegeven recurrente betrekking T(n), doe een ‚Äògoede gok‚Äô van de oplossing
<ul class="org-ul">
<li>Tip voor de gok: schrijf de recurrente betrekking een aantal stappen of geheel uit</li>
<li>Kijk of je hieruit iets kunt afleiden</li>
<li>Houd het simpel</li>
<li>Voeg extra termen/constantes toe indien nodig</li>
</ul></li>
</ul>

<p>
Zorg ervoor dat je je subsitutie doet met expliciete constanten. (dus geen \(O()\)).
</p>
<ul class="org-ul">
<li>Pas na je inductie-bewijs schat je af met \(O()\)</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="orgdc73a43"></a>Voorbeeld<br />
<div class="outline-text-5" id="text-1-4-1-1">
<ul class="org-ul">
<li>Voorbeeld: T(n) = T(n/2) + 1; T(1)=0</li>
<li>Gok: T(n) = log n. Gebruik nu inductie!</li>
<li>Basis: n=1: T(1) = 0; log n = 0. Correct!</li>
<li>IH: voor alle n‚Äô &lt; n geldt T(n‚Äô) = log n‚Äô</li>
<li>Stap: T(n) = T(n/2)+1 = log(n/2) + 1 = log n</li>
<li>Het bewijs volgt dus uit inductie</li>
</ul>

<p>
<b>MergeSort:</b>
</p>
<ul class="org-ul">
<li>\(T(n)=2T(n/2)+c\ n;\ T(1)=c'\)</li>
<li>Herinner: MergeSort in \(O(n\log n)\)</li>
<li>Gok: \(T(n)\le d\ n\log n\) voor te kiezen \(d (d\ge c'+c)\)</li>
<li>Gebruik inductie. Basis: \(n=2\)
<ul class="org-ul">
<li>\(T(2)\)</li>
<li>\(d\ n\log n = 2d\)</li>
<li>Als \(d\) tenminste \(c'+c\), dan is \(T(2)\le 2d\)</li>
</ul></li>
<li>Inductiehypothese: \(T(n')\le d\ n'\log n'\) voor alle \(n'<n\)</li>
<li>Stap:</li>
</ul>
<p>
\[T(n)=2T(n/2)+cn \]
\[\le 2d \frac n 2 \log \left(\frac n 2\right) + cn\]
\[=d\ n\left ( (\log n)-1\right)+cn\]
\[=d n \log n - dn + cn\]
</p>
<ul class="org-ul">
<li>Als \(d\ge c\), dan is \(T(n)\le d\ n \log n\)</li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org0bd94ac" class="outline-4">
<h4 id="org0bd94ac"><span class="section-number-4">1.4.2.</span> Recursieboom</h4>
<div class="outline-text-4" id="text-1-4-2">

<div id="orge2121ac" class="figure">
<p><img src="Divide_and_Conquer/2024-03-02_12-18-44_screenshot.png" alt="2024-03-02_12-18-44_screenshot.png" />
</p>
</div>
<ul class="org-ul">
<li>O(n) per niveau. Hoeveel niveaus?</li>
<li>Halveren tot grootte 1: n/2i=1 =&gt; i = log n</li>
<li>O(n log n) tij</li>
</ul>
</div>
</div>
<div id="outline-container-orga1230c2" class="outline-4">
<h4 id="orga1230c2"><span class="section-number-4">1.4.3.</span> master theorem</h4>
<div class="outline-text-4" id="text-1-4-3">
<p>
Uit het book van vierde editie, dit is de beste volgensmij
</p>
<ul class="org-ul">
<li>Stel \(a>0\), \(b>1\), \(g(n)\) een functie</li>
<li>Dan lost \(T(n)= a\ T(n/b)+g(n)\) op tot:
<ol class="org-ol">
<li>\(\Theta (n^p)\) als \(g(n)=O(n^e)\) voor \(e<p\)</li>
<li>\(\Theta (n^p \log^{k+1}n)\) als \(g(n)=\Theta(n^e\log ^k n)\) voor \(k\ge 0\) als \(e=p\)</li>
<li>\(\Theta(g(n))\) als \(g(n)=\Omega(n^e)\) voor \(e>p\) en er constante \(c<1\) bestaat zdd \(a\ g(n/b)\le c\ g(n)\)</li>
</ol></li>
<li>Hierbij is \(p=\log _b a\)</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org775c214"></a>Derde editie versie<br />
<div class="outline-text-5" id="text-1-4-3-1">
<p>
Iets simpeler, minder compleet
</p>

<ul class="org-ul">
<li>Stel \(a\ge 1\), \(b>1\), \(g(n)\) een functie</li>
<li>Dan lost \(T(n)= a\ T(n/b)+g(n)\) op tot:
<ol class="org-ol">
<li>\(\Theta (n^p)\) als \(g(n)=O(n^e)\) voor \(e<p\)</li>
<li>\(\Theta (n^p \log n)\) als \(g(n)=\Theta(n^e)\) voor \(e=p\)</li>
<li>\(\Theta(g(n))\) als \(g(n)=\Omega(n^e)\) voor \(e>p\) en er constante \(c<1\) bestaat zdd \(a\ g(n/b)\le c\ g(n)\)</li>
</ol></li>
<li>Hierbij is \(p=\log _b a\)</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org15820b3" class="outline-2">
<h2 id="org15820b3"><span class="section-number-2">2.</span> Recursief programmeren</h2>
<div class="outline-text-2" id="text-2">
<p>
Los deelproblemen op en voeg oplossingen samen
</p>
<ul class="org-ul">
<li>Deelproblemen kunnen wel overlappen</li>
<li>Vaak: alle mogelijkheden proberen</li>
<li>Bewijs correctheid: inductie</li>
<li>Werkt voor veel verschillende problemen
<ul class="org-ul">
<li>Grootste voordeel bij optimaliseringsproblemen</li>
</ul></li>
</ul>
</div>
<div id="outline-container-org1ffeea8" class="outline-3">
<h3 id="org1ffeea8"><span class="section-number-3">2.1.</span> Gepast betalen</h3>
<div class="outline-text-3" id="text-2-1">
<p>
<b>Optimaliseringsprobleem</b>:
</p>
<ul class="org-ul">
<li>Je moet deelverzameling/volgorde selecteren die optimaal is</li>
<li>In welke volgorde levert de postbode pakketjes af in zo kort mogelijke tijd?</li>
</ul>

<p>
Gegeven: positieve gehele getallen \(a_1,...,a_r\) (waarde munten), niet-negatief geheel getal \(b\) (doelbedrag)
</p>

<p>
Gevraagd: op welke manier kan \(b\) verkregen worden door zo min mogelijk munten van waardes \(a_1,...,a_r\) ?
</p>
<ul class="org-ul">
<li>Hoeveelheid munten van ieder soort is onbeperkt</li>
<li>Totale som moet b zijn.</li>
<li>We zoeken dus de aantallen \(x_1,...,x_r\in N = \{0,1,...\}\) met
<ul class="org-ul">
<li>\(\sum^r_{i=1}x_i\cdot a_i=b\)</li>
<li>en \(\sum_{i=1}^r x_i\) zo klein mogelijk</li>
</ul></li>

<li>Wat is de rij keuzes die leidt tot een oplossing?
<ul class="org-ul">
<li>Je kiest uit een aantal mogelijkheden waarvan er tenminste √©√©n tot een optimale oplossing leidt</li>
</ul></li>
<li>Identificeer de laatste keuze <b>(top-choice)</b>. Die leidt tot een splitsing in een deelprobleem</li>

<li><b>Top-choice:</b> de laatste munt die ik geef, zeg een munt van waarde \(a_i\)</li>
<li>Blijft over: Hoe kunnen we \(b-a_i\) gepast betalen met zo min mogelijk munten?</li>
<li>Deelprobleem: veralgemeniseer dit, want we weten \(a_i\) en dus \(b-a_i\) niet</li>
<li>Hoe kunnen we \(c\) gepast betalen met zo min mogelijk munten?</li>

<li>Deelprobleem: gegeven \(c\) met \(0 \le c \le b\) , hoe kunnen we \(c\) gepast betalen met zo min mogelijk munten?</li>
<li>Merk op: originele probleem is speciaal geval van deelprobleem (kies \(c = b\))</li>

<li>Wat is de rij keuzes die leidt tot een oplossing?
<ul class="org-ul">
<li>Je kiest uit een aantal mogelijkheden waarvan er tenminste √©√©n tot een optimale oplossing leidt</li>
</ul></li>
<li>Identificeer de laatste keuze (top-choice). Die leidt tot een splitsing in een deelprobleem</li>
<li>Gebruik top-choice en deelprobleem om een recursieve functie te maken
<ul class="org-ul">
<li>Let op de basisgevallen</li>
</ul></li>

<li>\(G(c)\) = kleinste aantal munten waarmee we c gepast kunnen betalen</li>
<li>Basisgeval: \(G(0) = 0\)</li>
<li>We geven munt van waarde \(a_i\) : \(G(c) = 1+G(c-a_i)\)</li>
<li>Essentieel: we proberen alle mogelijkheden en nemen de beste</li>
<li>\(G(c) = \min_i \{ 1 + G(c-a_i) \}\)
<ul class="org-ul">
<li>Minimum over alle i z.d.d. \(c \ge a_i\)</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgc177f72" class="outline-3">
<h3 id="orgc177f72"><span class="section-number-3">2.2.</span> optimaliteitsprincipe</h3>
<div class="outline-text-3" id="text-2-2">

<div id="orgb81bc0c" class="figure">
<p><img src="Recursief_programmeren/2024-02-21_10-45-11_screenshot.png" alt="2024-02-21_10-45-11_screenshot.png" />
</p>
</div>
<ul class="org-ul">
<li>Hoe weten we dat recursieve functie correct is?</li>
<li>Gebruik inductie!</li>
<li>Basisgeval: vaak triviaal (laten we hier achterwege)</li>
<li>Te bewijzen: als de top-choice gemaakt wordt volgens de optimale oplossing, dan is de optimale oplossing de juiste combinatie van optimale oplossingen van de deelproblemen</li>

<li>Probleem: gegeven \(c\) met \(0 \le c \le b\), hoe kunnen we \(c\) gepast betalen met zo min mogelijk munten?</li>
<li>\(T=\{m_1,..,m_k\}\) is optimale oplossing om \(c\) gepast te betalen. Zeg \(m_k\) waarde \(a_i\)</li>
<li>\(\{m_1,..,m_{k-1}\}\) is een manier om \(c-a_i\) gepast te betalen</li>
<li>Stel \(D =\{n_1,..,n_{k'}\}\) is optimale oplossing van deel- probleem om \(c-a_i\) gepast te betalen. Dan \(k' \le k -1\)</li>
<li>Laat \(T' = \{n_1,..n_{k'},m_k\}\). \(T'\) nog steeds een oplossing om \(c\) gepast te betalen</li>

<li>\(T=\{m_1,..,m_k\}\) , \(T' = \{n_1,..n_{k'},m_k\}\)</li>
<li>\(T\) en \(T'\) zijn een oplossing om \(c\) gepast te betalen</li>
<li>\(|T'| = k' +1 \le k = |T|\), want \(k' \le k -1\).</li>
<li>\(|T'| \ge |T|\), want \(T\) is optimaal</li>
<li>Dus \(|T'|=|T|\)</li>
<li>Dus optimale oplossing opgebouwd uit optimale oplossing voor deelprobleem</li>
<li>Optimaliteitsprincipe bewezen</li>
</ul>

<p>
Uitwisselargument:
<img src="Recursief_programmeren/2024-02-21_11-05-35_screenshot.png" alt="2024-02-21_11-05-35_screenshot.png" />
</p>
</div>
</div>
<div id="outline-container-orgbdc34d4" class="outline-3">
<h3 id="orgbdc34d4"><span class="section-number-3">2.3.</span> Samenvatting</h3>
<div class="outline-text-3" id="text-2-3">
<ul class="org-ul">
<li>Wat is de rij keuzes die leidt tot een oplossing?
<ul class="org-ul">
<li>Je kiest uit een aantal mogelijkheden waarvan er tenminste √©√©n tot een optimale oplossing leidt</li>
</ul></li>
<li>Identificeer de laatste keuze (top-choice). Die leidt tot een splitsing in een deelprobleem</li>
<li>Gebruik top-choice en deelprobleem om een recursieve functie te maken
<ul class="org-ul">
<li>Let op de basisgevallen</li>
</ul></li>
<li>Optimaliteitsprincipe: Als de top-choice gemaakt wordt volgens de optimale oplossing, dan is de optimale oplossing de juiste combinatie van optimale oplossingen van de deelproblemen</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgcc356a9" class="outline-2">
<h2 id="orgcc356a9"><span class="section-number-2">3.</span> Dynamisch Programmeren</h2>
<div class="outline-text-2" id="text-3">
<p>
Twee mogelijkheden:
</p>
<ul class="org-ul">
<li><b>Memoisatie:</b> kijk of we ‚Äòt al eerder hebben uitgerekend ‚Äì zo ja, geef dat antwoord; zo nee: reken uit en sla antwoord op in datastructuur (bijvoorbeeld array of hashtabel)</li>
<li><b>&rsquo;Klassiek&rsquo; DP:</b> vul datastructuur met antwoorden voor deelproblemen, zodat nodige gegevens al eerder zijn berekend</li>
</ul>
</div>
<div id="outline-container-org0b7e616" class="outline-3">
<h3 id="org0b7e616"><span class="section-number-3">3.1.</span> Driehoek van Pascal DP</h3>
</div>
<div id="outline-container-org33d062b" class="outline-3">
<h3 id="org33d062b"><span class="section-number-3">3.2.</span> Klassiek DP</h3>
<div class="outline-text-3" id="text-3-2">
<ul class="org-ul">
<li>Initialiseer array</li>
<li>Vul de basisgevallen in</li>
<li>Vul de array, lettend op de opvul-volgorde
<ul class="org-ul">
<li>Vul van basis naar eind-antwoord</li>
</ul></li>
<li>Return oplossing</li>
</ul>
</div>
<div id="outline-container-orged16b8d" class="outline-4">
<h4 id="orged16b8d"><span class="section-number-4">3.2.1.</span> Ontwerp</h4>
<div class="outline-text-4" id="text-3-2-1">
<ul class="org-ul">
<li>Wat is de rij keuzes die leidt tot een oplossing?
<ul class="org-ul">
<li>Je kiest uit een aantal mogelijkheden waarvan er tenminste √©√©n tot een optimale oplossing leidt</li>
</ul></li>
<li>Identificeer de laatste keuze (top-choice). Die leidt tot een splitsing in een deelprobleem</li>
<li>Gebruik top-choice en deelprobleem om een recursieve functie te maken
<ul class="org-ul">
<li>Let op de basisgevallen</li>
</ul></li>
<li>Optimaliteitsprincipe: Als de top-choice gemaakt wordt volgens de optimale oplossing, dan is de optimale oplossing de juiste combinatie van optimale oplossingen van de deelproblemen</li>
<li>Vind de juiste berekeningsvolgorde
<ul class="org-ul">
<li>Memoisatie volgt uit recursieve functie</li>
<li>Opletten bij DP algoritme</li>
</ul></li>
<li>Eventueel: geheugenbesparing of oplossing vinden</li>
</ul>

<p>
<b>Technieken die vaak werken</b>
</p>
<ul class="org-ul">
<li>Terugredeneren van antwoord</li>
<li>Bijhouden van extra informatie die vertelt waar je vandaan komt, of dit later zien aan de opgeslagen informatie</li>
</ul>

<p>
<b>Versies van problemen</b>
</p>
<ul class="org-ul">
<li>Optimalisatieprobleem
<ul class="org-ul">
<li>Wat is het kleinste aantal munten waarmee \(b\) betaald kan worden met munten van waardes \(a_1, ... , a_r\)? (Antwoord is een getal.)</li>
</ul></li>
<li>Constructieprobleem
<ul class="org-ul">
<li>Op welke manier kan \(b\) betaald worden met zo min mogelijk munten van waardes \(a_1, ... , a_r\)? (Antwoord is een serie van waardes van munten.)</li>
</ul></li>
<li>Beslissingsprobleem
<ul class="org-ul">
<li>Vb: kan \(b\) betaald worden met hooguit i munten van waardes \(a_1, ... , a_r\)? (Antwoord is: JA of NEE.)</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org33a52e5" class="outline-4">
<h4 id="org33a52e5"><span class="section-number-4">3.2.2.</span> Constructieversies</h4>
<div class="outline-text-4" id="text-3-2-2">
<ol class="org-ol">
<li>Doe eerst DP algoritme voor beslisprobleem of optimalisatieprobleem
<ul class="org-ul">
<li>Eventueel met bijhouden van extra gegevens</li>
</ul></li>
<li>Construeer antwoord achterstevoren door gebruik te maken van de opgeslagen en door het DP algoritme berekende informatie
<ul class="org-ul">
<li>Bijvoorbeeld: hoe werd het minimum/maximum berekend?</li>
</ul></li>
</ol>

<p>
zie slides vanaf 44 voor voorbeeld
</p>
</div>
</div>
<div id="outline-container-orgb87a556" class="outline-4">
<h4 id="orgb87a556"><span class="section-number-4">3.2.3.</span> Voorbeeld: gepast betalen:</h4>
<div class="outline-text-4" id="text-3-2-3">
<ul class="org-ul">
<li>\(G(c) = \min_i \{ 1 + G(c-a_i) \}\)
<ul class="org-ul">
<li>Minimum over alle i z.d.d. \(c \ge a_i\)</li>
</ul></li>
<li>Basisgeval: \(G(0) = 0\)</li>
</ul>

<p>
Method \(Gepast(a_1,..,a_r,b)\)
</p>
<ul class="org-ul">
<li>Maak array G[0..b]; G[0] = 0; G[1..b] = ‚àû</li>
<li>for c = 1 to b do // nu het minimum berekenen
<ul class="org-ul">
<li>for i = 1 to r do
<ul class="org-ul">
<li>if \(c \ge a_i\) then \(G[c] = \min\{G[c], 1+ G[c-a_i] \}\)</li>
</ul></li>
</ul></li>
<li>return G[b]</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgda768dd" class="outline-3">
<h3 id="orgda768dd"><span class="section-number-3">3.3.</span> Keuzes/deelproblemen identificeren</h3>
<div class="outline-text-3" id="text-3-3">
<p>
Let goed op de probleemstelling
</p>
<ul class="org-ul">
<li>Zit er een volgorde die gebruikt kan worden?</li>
<li>Wat wil je optimaliseren</li>
</ul>

<p>
Identificeer de top-choice
</p>
<ul class="org-ul">
<li>Welke beslissingen kan het optimum nemen?</li>
</ul>

<p>
Bekijk de situatie die overblijft na een top-choice
</p>
</div>
</div>
<div id="outline-container-org1d33ad1" class="outline-3">
<h3 id="org1d33ad1"><span class="section-number-3">3.4.</span> Traveling Salesman problem</h3>
<div class="outline-text-3" id="text-3-4">
<p>
Een handelsreiziger moet n steden bezoeken:
</p>
<ul class="org-ul">
<li>Bezoek elke stad 1 keer</li>
<li>Elk paar steden v, w heeft een afstand \(d(v,w)\)</li>
<li>Beginstad = eindstad</li>
<li>Wat is de kortste route?</li>
</ul>

<p>
<b>Top choice</b>: laatste bezochte adres
</p>

<p>
Deelprobleem hier is minder makkelijk, je kan niet zeggen hoe kan ik het snelste de eerste i adressen bezoeken. Snelste route voor eerste drie adressen hoeft geen deel te zijn van een snelste route voor eerste vier adressen.
</p>

<p>
<b>Deelprobleem</b>: Gegeven een verzameling adressen \(s\) en een adres \(k\), wat is de minimum tijd om alle adressen in \(S\) te bezoeken, beginnend bij depot en eindigend bij adres \(k\)?
</p>
<ul class="org-ul">
<li>Handige notatie: \(s\) is alle adressen die we bezoeken tussen het depot en het bezoek aan adres \(k\), dus we bezoeken \(s\cup\) {depot, k}</li>
</ul>

<p>
Merk op: algemene probleem is speciaal geval van deelprobleem
</p>
<ul class="org-ul">
<li>Bekijk optimale oplossing en kies k als laatste adres en S = {1,‚Ä¶,n}\{k}</li>
</ul>

<p>
\(A(S,k) =\) minimum tijd van trip als we beginnen in depot, dan alle adressen in S bezoeken (met de beste volgorde) en dan naar adres k gaan
</p>

<p>
Neem beste optie van alle mogelijke laatst bezochte adressen k
</p>

<p>
\(\min\{A(V-\{k\},k)+ d(k,depot)|k\in V\}\)
</p>
<ul class="org-ul">
<li>\(d(k,depot)\) geeft tijd voor laatste stap van k terug naar depot</li>
</ul>

<div class="org-src-container">
<pre class="src src-c"><span style="color: #eeddaa;">Method</span> <span style="color: #88aaee;">HK</span>(V = {depot, <span style="color: #eeaa77;">1</span>, ..,n})
Maak een <span style="color: #eeddaa;">hashtabel</span> <span style="color: #ccccee;">Q</span>, <span style="color: #ccccee;">initieel</span> leeg
best = &#8734;
forall &#119896; &#8712; {<span style="color: #eeaa77;">1</span>, &#8230; , &#119899;} <span style="color: #bb99ee;">do</span> <span style="color: #666677;">// </span><span style="color: #666677;">loop door alle depots</span>
        <span style="color: #666677;">// </span><span style="color: #666677;">zie k als eindpunt van route, doe daar bij de afstand van k tot depot</span>
        best = min{ best, HKrec(&#119881; &#8722; {&#119896;}, &#119896;) + d(&#119896;, depot) }
<span style="color: #bb99ee;">return</span> best

<span style="color: #666677;">// </span><span style="color: #666677;">functie om afstand van route adress g tot depot te bereken door S lopend</span>
Method HKrec(&#119878;, &#119892;) <span style="color: #666677;">// </span><span style="color: #666677;">volg recursieve functie</span>
<span style="color: #bb99ee;">if</span> &#119878;, &#119892; &#8712; &#119876; then <span style="color: #bb99ee;">return</span> &#119876;(&#119878;, &#119892;)
<span style="color: #bb99ee;">else</span>
    <span style="color: #bb99ee;">if</span> &#119878; = &#8709; then <span style="color: #bb99ee;">return</span> &#119889; &#119889;&#119890;&#119901;&#119900;&#119905;, &#119892;
    <span style="color: #bb99ee;">else</span> &#119886;&#119899;&#119905;&#119908; = &#8734;;
        <span style="color: #bb99ee;">for</span> &#119896; &#8712; &#119878; <span style="color: #bb99ee;">do</span>
            <span style="color: #666677;">// </span><span style="color: #666677;">recursieve call, afstand van k door de rest plus afstand tussen k en g</span>
            &#119886;&#119899;&#119905;&#119908; = min{&#119886;&#119899;&#119905;&#119908;, HKrec (&#119878; &#8211; &#119896; , &#119896;) + &#119889; (&#119896;, &#119892;) }
        <span style="color: #88aaee;">&#119876;</span>(&#119878;, &#119892;) = &#119886;&#119899;&#119905;&#119908;
        <span style="color: #bb99ee;">return</span> &#119886;&#119899;&#119905;&#119908;
</pre>
</div>

<p>
Andere aanpak: hier gaan we een soort van vanaf het depot rekenen en telkens alle afstanden bijhouden
</p>

<p>
Reken alle ùê¥(ùëÜ, ùëî) uit:
</p>
<ul class="org-ul">
<li>Eerst alleen ùëÜ = ‚àÖ</li>
<li>Dan alle ùëÜ met √©√©n adres</li>
<li>Dan alle ùëÜ met twee adressen</li>
<li>Dan alle ùëÜ met drie adressen</li>
<li>Etc</li>
</ul>

<p>
Of representeer ùëÜ als integer ‚Ä¶
</p>

<p>
Practisch: reken bij elke verzameling de ‚Äúopvolgende oplossingen‚Äù uit (met heuristieken om stukken die nooit optimaal kunnen zijn weg te laten)
</p>
</div>
<div id="outline-container-orgbb84f22" class="outline-4">
<h4 id="orgbb84f22"><span class="section-number-4">3.4.1.</span> Complexiteit</h4>
<div class="outline-text-4" id="text-3-4-1">
<ul class="org-ul">
<li>Tijd: we kijken naar alle deelverzamelingen: 2ùëõ</li>
<li>Per verzameling ùëõ keuzes voor laatste adres</li>
<li>Per combinatie ùëõ tijd, want kijken naar elk een-na- laatste adres:</li>
<li>\(O(2^n n^2)\)</li>
<li>Generalisatie: bijvoorbeeld: hoeveel adressen kan je binnen ùëò tijd bezoeken? (openingstijd van een winkelgebied?)</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org6bde84c" class="outline-2">
<h2 id="org6bde84c"><span class="section-number-2">4.</span> Greedy algorithms</h2>
<div class="outline-text-2" id="text-4">
<p>
Greedy algorithms are those which build the solution step-by-step, making the optimal choice at every step.
</p>

<p>
To show the correctness of the greedy strategy, one needs to prove the following:
</p>
<ul class="org-ul">
<li><b>Greedy Choice Property:</b> We need to prove that the greedy choice that we make, indeed yields an optimal solution. To do so, we show that there exists some optimal solution that contains the best option as per our greedy strategy.</li>
<li><b>Optimality Principle:</b> To demonstrate optimal substructure of the problem, we need to show that if we combine the greedy choice with the optimal solution of the subproblem we are left with, we get the optimum solution to the original problem.</li>
</ul>

<p>
To show if a problem has the greedy choice property consider an optimal solution that does not contain your greedy choice.
</p>
<ul class="org-ul">
<li><b>Exchange Argument:</b> Modify the solution by replacing some part of it with your greedy choice. Show that the modified solution preserves optimality.</li>
</ul>
</div>
<div id="outline-container-orgf3692c8" class="outline-3">
<h3 id="orgf3692c8"><span class="section-number-3">4.1.</span> Fractional Knapsack problem, Interval Scheduling en Huffman&rsquo;s codes</h3>
<div class="outline-text-3" id="text-4-1">
<p>
Niet super boeiend best simple, bewijs is wel handig om even door te lezen in de lecture notes.
</p>
</div>
</div>
</div>
<div id="outline-container-org8b96435" class="outline-2">
<h2 id="org8b96435"><span class="section-number-2">5.</span> Graphs</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-org0d66541" class="outline-3">
<h3 id="org0d66541"><span class="section-number-3">5.1.</span> Graph representation</h3>
<div class="outline-text-3" id="text-5-1">
<p>
\(G=(V,E)\)
</p>
<ul class="org-ul">
<li>V: set of vertices in the graps (dots)
<ul class="org-ul">
<li>\(n=|v|\)</li>
<li>Example : \(V={a,b,c,d,e}\)</li>
</ul></li>
<li>E: set of edges in the graph (lines)
<ul class="org-ul">
<li>\(m=|E|\)</li>
<li>Example: \(E=\{(a, b), (a, c), (b, c), (c, d)\}\)</li>
</ul></li>
</ul>

<p>
In directed graphs, the edges are ordered set. That is, \((u,v)\ne (v,u)\)
<img src="Graphs/2024-02-22_09-08-27_screenshot.png" alt="2024-02-22_09-08-27_screenshot.png" />
</p>

<p>
Weighted graph: the edges can be associated with weights.
<img src="Graphs/2024-02-22_09-10-03_screenshot.png" alt="2024-02-22_09-10-03_screenshot.png" />
</p>

<p>
Terminologies:
<img src="Graphs/2024-02-22_09-10-21_screenshot.png" alt="2024-02-22_09-10-21_screenshot.png" />
</p>
</div>
</div>
<div id="outline-container-org202790e" class="outline-3">
<h3 id="org202790e"><span class="section-number-3">5.2.</span> Adjacency list</h3>
<div class="outline-text-3" id="text-5-2">
<p>
For each vertex, store its neighbors in a linked list
</p>
<ul class="org-ul">
<li>Space complexity: \(O(|E|)\)</li>
<li>Querying complexity: \(O(max\ degree)\)</li>
</ul>


<div id="org3f0a71d" class="figure">
<p><img src="Graphs/2024-02-22_09-15-25_screenshot.png" alt="2024-02-22_09-15-25_screenshot.png" />
</p>
</div>
</div>
</div>
<div id="outline-container-org3db8305" class="outline-3">
<h3 id="org3db8305"><span class="section-number-3">5.3.</span> Adjacency Matrix</h3>
<div class="outline-text-3" id="text-5-3">

<div id="orge2854dc" class="figure">
<p><img src="Graphs/2024-02-22_09-21-03_screenshot.png" alt="2024-02-22_09-21-03_screenshot.png" />
</p>
</div>

<p>
Use a \(|V|\times |V|\) matrix A such that
</p>
<ul class="org-ul">
<li>\(A(u,v)=1\) iff \((u,v)\in E\)</li>
<li>\(A(u,v)=0\) otherwise</li>

<li>Space complexity: \(O(|V|^2)\)</li>
<li>Querying complexity: \(O(1)\)</li>
<li>For directed graphs, A is not necessarily symmetric</li>
</ul>
</div>
</div>
<div id="outline-container-orge694447" class="outline-3">
<h3 id="orge694447"><span class="section-number-3">5.4.</span> Adjacency List and Adjacency Matrix</h3>
<div class="outline-text-3" id="text-5-4">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">Adjacency list</th>
<th scope="col" class="org-left">Adjacency matrix</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Space</td>
<td class="org-left">\(O(V+E)\)</td>
<td class="org-left">\(O(V^2)\)</td>
</tr>

<tr>
<td class="org-left">Add an edge</td>
<td class="org-left">\(O(1)\)</td>
<td class="org-left">\(O(1)\)</td>
</tr>

<tr>
<td class="org-left">Delete an edge</td>
<td class="org-left">\(O(max degree) = O(V)\)</td>
<td class="org-left">\(O(1)\)</td>
</tr>

<tr>
<td class="org-left">List all neighbors of a vertex</td>
<td class="org-left">\(O(# of neighbors) = O(V)\)</td>
<td class="org-left">\(O(V)\)</td>
</tr>

<tr>
<td class="org-left">Check adjacency of vertices u and v</td>
<td class="org-left">\(O(max degree) = O(V)\)</td>
<td class="org-left">\(O(1)\)</td>
</tr>

<tr>
<td class="org-left">List all edges</td>
<td class="org-left">\(O(E)\)</td>
<td class="org-left">\(O(V^2)\)</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-orga5c819b" class="outline-3">
<h3 id="orga5c819b"><span class="section-number-3">5.5.</span> Depth-First Search</h3>
<div class="outline-text-3" id="text-5-5">
<div class="org-src-container">
<pre class="src src-c">Procedure DFS-VISIT(u)
    Mark u as discovered
    time &#8592; time + <span style="color: #eeaa77;">1</span>
    d[u] &#8592; time
    For each neighbor v of u
        If v is not-discovered
            &#960;[v] &#8592; u
            DFS-VISIT(v)
    Mark u as finished
    time &#8592; time + <span style="color: #eeaa77;">1</span>
    f[u] &#8592; time
</pre>
</div>
<ul class="org-ul">
<li>For each of the vertices v, we take information:</li>
<li>\(d[v]\): discover time, timestamp when is first discovered</li>
<li>\(f[v]\): finish time, timestamp when the search finishes examining \(v\)‚Äôs adjacency list
<ul class="org-ul">
<li>\(d[v]<f[v]\le 2|V|\)</li>
</ul></li>
<li>\(\pi[v]\): the predecessor of \(v\) when we traverse the graph</li>
</ul>
</div>
<div id="outline-container-orge8a852d" class="outline-4">
<h4 id="orge8a852d"><span class="section-number-4">5.5.1.</span> Parenthesis Theorem</h4>
<div class="outline-text-4" id="text-5-5-1">
<p>
In any DFS of a graph \(G=(V,E)\), for any two vertices \(u,v\in V\), there are three cases of the positions of u and v in the depth-first forest
</p>
<ul class="org-ul">
<li>\(u\) is a descendant of \(v\)
<ul class="org-ul">
<li>\([d[u]], f[u]]\) is contained entirely within \([d[v],f[v]]\)</li>
</ul></li>
<li>\(v\) is a descendant of \(u\), or
<ul class="org-ul">
<li>\([d[v],f[v]]\) is contained entirely within \([d[u],f[u]]\)</li>
</ul></li>
<li>neither \(u\) nor \(v\) is a descendant of the other
<ul class="org-ul">
<li>\([d[u],f[u]]\) and \([d[v],f[v]]\) are entirely disjoint</li>
</ul></li>
</ul>


<div id="org5caddee" class="figure">
<p><img src="Graphs/2024-02-22_10-03-04_screenshot.png" alt="2024-02-22_10-03-04_screenshot.png" />
</p>
</div>

<p>
<b>Theorem:</b> In any DFS of a graph \(G=(V,E)\), for any two vertices \(u,v\in V\), \(v\) is a proper descendant of \(u\) in the depth-first forest if and only if \(d[u]<d[v]<f[v]<f[u]\)
</p>
</div>
</div>
<div id="outline-container-org3f6fdbd" class="outline-4">
<h4 id="org3f6fdbd"><span class="section-number-4">5.5.2.</span> Edges Classification</h4>
<div class="outline-text-4" id="text-5-5-2">
<p>
According to the Depth-first forest \(G_\pi(V,E_\pi)\), each edge \((u,v)\in E\) is on of for type
</p>
<ul class="org-ul">
<li>Tree edges: the edges in \(E_\pi\)
<ul class="org-ul">
<li>(u,v) is a tree edge if v was first discovered by exploring edge (u,v)</li>
</ul></li>
<li>Back edges: pointing from a descendant to an ancestor</li>
<li>Forward edges: non-tree-edges pointing from an ancestor to a descendant</li>
<li>Cross edges: all other edges</li>
</ul>


<div id="orgd57f94c" class="figure">
<p><img src="Graphs/2024-02-22_10-10-01_screenshot.png" alt="2024-02-22_10-10-01_screenshot.png" />
</p>
</div>
</div>
</div>
<div id="outline-container-org86b5adf" class="outline-4">
<h4 id="org86b5adf"><span class="section-number-4">5.5.3.</span> White-Path Theorem</h4>
<div class="outline-text-4" id="text-5-5-3">
<p>
In a depth-first forest of a graph \(G\), vertex \(v\) is a descendant of \(u\) vertex if and only if at the time that \(u\) is discovered by DFS, vertex \(v\) can be reached from \(u\) along a path consisting entirely of white vertices.
</p>

<p>
Application: Cycle Detection
</p>
<ul class="org-ul">
<li>Given a directed graph \(G\), there is a directed cycle if and only if a DFS of \(G\) yields at least one back edge.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgabf6750" class="outline-3">
<h3 id="orgabf6750"><span class="section-number-3">5.6.</span> Directed Acyclic Graph</h3>
<div class="outline-text-3" id="text-5-6">
<p>
A <b>directed acyclic graph (DAG)</b> is a directed graph which does not have any directed cycles
</p>
<ul class="org-ul">
<li>So no back edges in the graph</li>
</ul>

<p>
A <b>topological sort</b> of a DAG is a linear ordering of all its vertices such that for any edge \((u,v)\in E\), u appears before v in the ordering
</p>

<div class="org-src-container">
<pre class="src src-python">Procedure Topological<span style="color: #88ccdd;">-</span>Sort(G)
   Linked <span style="color: #ee8899;">list</span> L_sort <span style="color: #88ccdd;">&lt;-</span> NIL
   Call DFS(G)
   As each vertex v <span style="color: #bb99ee;">is</span> finished
      Put v to the front of L_sort
   Return L_sort
</pre>
</div>

<p>
Same time complexity as DFS
</p>
</div>
</div>
<div id="outline-container-org817f940" class="outline-3">
<h3 id="org817f940"><span class="section-number-3">5.7.</span> Strongly connected component</h3>
<div class="outline-text-3" id="text-5-7">
<p>
A strongly connected component of a directed graph \(G=(V,E)\) is a maximal set of vertices \(C\subseteq V\) such that for every pair of vertices u and v in C, there is a path from u to v and a path from v to u. That is, u and v are reachable from each other.
</p>


<div id="orgea36e78" class="figure">
<p><img src="Deel_1/2024-05-09_16-02-26_screenshot.png" alt="2024-05-09_16-02-26_screenshot.png" />
</p>
</div>



<div id="org8ec41df" class="figure">
<p><img src="Deel_1/2024-05-09_16-02-53_screenshot.png" alt="2024-05-09_16-02-53_screenshot.png" />
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org070655d" class="outline-2">
<h2 id="org070655d"><span class="section-number-2">6.</span> Single source shortest path</h2>
<div class="outline-text-2" id="text-6">
<p>
The problem:
</p>
<ul class="org-ul">
<li>A directed graph \(G=(V,E,w)\)</li>
<li>Where every edge \((u,v)\in E\) has a weight \(w(u,v)\)</li>
<li>A path P is a sequence of vertices \(v_0, ..., v_k\) path that for any \(i \in [1,k],\ (v_{i-1},v_i)\in E\).</li>
<li>The weight of a path P, denoted by w(P), is defined by \(\sum^k_{i=1}w(v_{i-1},v_i)\)</li>
<li>We denote te shortest distance between \(u,v \in V\), \(\delta(u,v)\) by \(\min \{w(P)|P\text{ is a path from u to v}\}\)</li>
<li>The <b>single-source shortest paths</b> problem is to find the shortest distance from the source to any vertex \(v\in V\)</li>
</ul>

<p>
In the next paragraphs the following variables are used:
</p>
<ul class="org-ul">
<li>\(d[v]\): the distance from the source s to it</li>
<li>\(\pi [v]\): the predecessor of v when we traverse the graph</li>
</ul>
</div>
<div id="outline-container-orge47116b" class="outline-3">
<h3 id="orge47116b"><span class="section-number-3">6.1.</span> Breadth-First Search: unweighted graph or graph with uniform weight</h3>
<div class="outline-text-3" id="text-6-1">
<p>
BFS keeps a queue of visited virtices. In each round, BFS dequeues a vertex from the queue and enqueues all its neighbors that are not discovered yet.
</p>


<div id="org71a293f" class="figure">
<p><img src="Single_source_shortest_path/2024-06-28_20-03-44_screenshot.png" alt="2024-06-28_20-03-44_screenshot.png" />
</p>
</div>

<p>
Time complexity of \(O(|V|+|E|)\): every vertex is enqueued and dequeued once, and each edge is checked once.
</p>
</div>
</div>
<div id="outline-container-orge03ba8f" class="outline-3">
<h3 id="orge03ba8f"><span class="section-number-3">6.2.</span> Tense edges and relaxation</h3>
<div class="outline-text-3" id="text-6-2">
<p>
\(d[v]\) is the temporal estimation (initially \(\infty\)) of the shortest distance from s to v. We keep updating it when we find an shorter distance from s to v.
</p>

<p>
An edge \((u,v)\) is <b>tense</b> if \(d[v] > d[u] + w(u,v)\)
</p>

<p>
We relax a tense edge by udating the value of \(d[v]\) to \(d[v]+w(u,v)\)
</p>

<p>
Throughout the single-source shorest paths algoriths, we keep relaxing tense edges if there are any.
</p>

<p>
Using these concept we can rewrite BFS like this
</p>


<div id="orgdbbad47" class="figure">
<p><img src="Single_source_shortest_path/2024-06-28_20-33-07_screenshot.png" alt="2024-06-28_20-33-07_screenshot.png" />
</p>
</div>
</div>
</div>
<div id="outline-container-org42e72c7" class="outline-3">
<h3 id="org42e72c7"><span class="section-number-3">6.3.</span> Weighted DAG single source shortest path</h3>
<div class="outline-text-3" id="text-6-3">

<div id="org3343fa2" class="figure">
<p><img src="Single_source_shortest_path/2024-06-28_20-34-45_screenshot.png" alt="2024-06-28_20-34-45_screenshot.png" />
</p>
</div>


<div id="org84fa788" class="figure">
<p><img src="Single_source_shortest_path/2024-06-28_20-40-40_screenshot.png" alt="2024-06-28_20-40-40_screenshot.png" />
</p>
</div>

<p>
Also time complexity of \(O(|V|+|E|)\)
</p>
</div>
</div>
<div id="outline-container-org7ff856c" class="outline-3">
<h3 id="org7ff856c"><span class="section-number-3">6.4.</span> Dijkstras algorithm: weigthed graph with non-negagive weight</h3>
<div class="outline-text-3" id="text-6-4">
<p>
It can be looked at as bfs but by replacing the normal queue with a priority queue
</p>


<div id="orgd115a73" class="figure">
<p><img src="Single_source_shortest_path/2024-06-28_20-54-16_screenshot.png" alt="2024-06-28_20-54-16_screenshot.png" />
</p>
</div>

<p>
Time complexity: \(O(|V|^2)\), this can be improved to \(O(|E|+|V|\log|V|)\)
</p>
</div>
</div>
<div id="outline-container-org3e4dd5b" class="outline-3">
<h3 id="org3e4dd5b"><span class="section-number-3">6.5.</span> Bellman-Ford: weigthed graph without negative cycle</h3>
<div class="outline-text-3" id="text-6-5">

<div id="org32fa95f" class="figure">
<p><img src="Single_source_shortest_path/2024-06-28_21-07-59_screenshot.png" alt="2024-06-28_21-07-59_screenshot.png" />
</p>
</div>

<p>
Time complexity is \(O(|V||E|)\): There is no shortest path with more than |V | ‚àí 1 edges. Therefore, the Bellman-Ford algorithm takes at most |V | ‚àí 1 rounds, and each round takes at most |E| checking and relaxation.
</p>
</div>
</div>
</div>
<div id="outline-container-org2333217" class="outline-2">
<h2 id="org2333217"><span class="section-number-2">7.</span> All pair shortest paths</h2>
<div class="outline-text-2" id="text-7">
<p>
We want to know the shortest path from every possible source to every possible destination.
</p>

<p>
The algorithm should return \(\delta(u,v)\) for any pairs of vertices \(u\) and \(v\).
</p>


<div id="orgea8fa45" class="figure">
<p><img src="All_pair_shortest_paths/2024-06-29_13-00-26_screenshot.png" alt="2024-06-29_13-00-26_screenshot.png" />
</p>
</div>
</div>
<div id="outline-container-orgf43e525" class="outline-3">
<h3 id="orgf43e525"><span class="section-number-3">7.1.</span> Lots of single sources</h3>
<div class="outline-text-3" id="text-7-1">
<p>
A naive approach is simply running a single source algorithm on every vertex.
</p>

<p>
For graphs with non negative weights Dijkstra can be used. For the general case Bellman-Ford can be used.
<img src="All_pair_shortest_paths/2024-06-29_10-57-16_screenshot.png" alt="2024-06-29_10-57-16_screenshot.png" />
</p>

<p>
For dijkstra this will result in a timecomplexity of \(O(|V|^2\log |V|+|V||E|)\) using the fibonacci heap.
</p>

<p>
For Bellman-ford the time-complexity is \(O(|V|^2|E|)=O(|V|^4)\)
</p>
</div>
</div>
<div id="outline-container-orgcee580d" class="outline-3">
<h3 id="orgcee580d"><span class="section-number-3">7.2.</span> DP by length</h3>
<div class="outline-text-3" id="text-7-2">
<p>
We define \(dist^{(l)}_{uv}\): the shortest distance from vertex u to vertex v, containing at most l edges
<img src="All_pair_shortest_paths/2024-06-29_11-20-06_screenshot.png" alt="2024-06-29_11-20-06_screenshot.png" />
</p>

<p>
This has a complexity of: \(O(|V|^2|E|)=O(|V|^4)\)
</p>

<p>
This algorithm can be improved upon by doubling the amount of involved edges each round.
</p>


<div id="org1a12b85" class="figure">
<p><img src="All_pair_shortest_paths/2024-06-29_11-43-08_screenshot.png" alt="2024-06-29_11-43-08_screenshot.png" />
</p>
</div>
</div>
</div>
<div id="outline-container-org728e01c" class="outline-3">
<h3 id="org728e01c"><span class="section-number-3">7.3.</span> Floyd-Warhall algorithm</h3>
<div class="outline-text-3" id="text-7-3">
<p>
This is also a dynamic programming base approach.
</p>

<p>
Number the vertices \(1,2,3,...,|V|\)
</p>

<p>
\(dist^{(k)}_{uv}\): the shortest distance form vertex u to vertex v, only going through vertices \(\{1,2,3,...,k\}\) (doesn&rsquo;t have to go through all vertices.)
</p>


<div id="orge7b4beb" class="figure">
<p><img src="All_pair_shortest_paths/2024-06-29_12-02-54_screenshot.png" alt="2024-06-29_12-02-54_screenshot.png" />
</p>
</div>

<p>
Time complexity: \(O(|V|^3)\)
</p>

<p>
Uitleg hoe dit algoritme werkt in het boek
</p>
</div>
</div>
<div id="outline-container-org1e52358" class="outline-3">
<h3 id="org1e52358"><span class="section-number-3">7.4.</span> Johsons algorithm</h3>
<div class="outline-text-3" id="text-7-4">
<p>
We want to reweigh the edge so that there are no negative weights. Then just run Dijkstra&rsquo;s algorithm again on every vertex again.
</p>

<p>
We can&rsquo;t simply add some constant to each weight, this doesn&rsquo;t always preserve the same longest path.
</p>

<p>
The new weights \(w'(u,v)\) for any edge \((u,v)\) should satisfy the following properties:
</p>
<ul class="org-ul">
<li>For all edges (u,v), the new weight \(w'(u,v)\) is non-negative</li>
<li>P is the shortest path from s to t using the original weights if and only if P is the shortest path from s to t in the original graph with new weights
<ul class="org-ul">
<li>For all pair of vertices \(s,t\in V\) and a shortest path P from s to t, \(w(P)=\delta(s,t)\) if and only if \(w'(P)=\delta'(s,t)\)</li>
</ul></li>
</ul>

<p>
The re-weighting:
</p>
<ul class="org-ul">
<li>Every vertex v has a value \(h(v)\)</li>
<li>The new weight: \(w'(u,v)=h(u)+w(u,v)-h(v)\)</li>
</ul>

<p>
Proof that this preserves the shortest path can be found in the slides.
</p>

<p>
H is defined by adding a vertex to the graph that has an outgoing edge to each other vertex. Then bellman ford is ran from the new vertex, the h-value is the shortest path from the new vertex.
</p>


<div id="org495067b" class="figure">
<p><img src="All_pair_shortest_paths/2024-06-29_12-55-30_screenshot.png" alt="2024-06-29_12-55-30_screenshot.png" />
</p>
</div>


<div id="orga678b49" class="figure">
<p><img src="All_pair_shortest_paths/2024-06-29_12-55-53_screenshot.png" alt="2024-06-29_12-55-53_screenshot.png" />
</p>
</div>

<p>
After calculating the h-values we can reweight all edges, run dijkstra and finally return the weights to the old value.
</p>


<div id="org8786ed4" class="figure">
<p><img src="All_pair_shortest_paths/2024-06-29_12-58-01_screenshot.png" alt="2024-06-29_12-58-01_screenshot.png" />
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orgc2984f7" class="outline-2">
<h2 id="orgc2984f7"><span class="section-number-2">8.</span> Matchings</h2>
<div class="outline-text-2" id="text-8">
<p>
chapter 25
</p>
<ul class="org-ul">
<li>Book defines flow as something between vertices, instead as something belonging to an arc
<ul class="org-ul">
<li>Connections between each vertex in the book kindoff</li>
</ul></li>
</ul>
</div>
<div id="outline-container-orgabb7b28" class="outline-3">
<h3 id="orgabb7b28"><span class="section-number-3">8.1.</span> Matchings</h3>
<div class="outline-text-3" id="text-8-1">
<p>
<b>Matching:</b> Subset of edges  that do not have a common endpoint.
</p>

<p>
Matching M is <b>maximum</b> if there is no matching with more number of edges.
</p>

<p>
A <b>maximal</b> matching is a matching M to which no other edges can be added.
</p>

<p>
To create a maximum matching we use a greedy algorithm, given a non maximum matching create a bigger matching from it.
</p>

<p>
Given a matching M in an undirected graph \(G=(V,E)\), an <b>M-alternating</b> path is a simple path whose edges alternate between being in M and being in \(E-M\).
</p>

<p>
<b>M-augmenting path</b> (sometimes called an augmenting path with respect to M ): an M-alternating path whose first and last edges belong to \(E-M\) (not in the matching). This means the first and last vertex are also unmatched. <a id="orgda1084a"></a>
</p>

<p>
<i>In the slides the above two definition are given as the same (both the same as M-augmenting)</i>
</p>

<p>
Larger matching M&rsquo;: exchange edges of M-augmenting path P
</p>
<ul class="org-ul">
<li>\(e\in P \setminus M\) (edges in the path but not in the matching): put in M&rsquo;</li>
<li>\(e\in P\cap M\) (edges in both the path and the matching): don‚Äôt put in M&rsquo;</li>
<li>Other edges of M: put in M&rsquo;</li>
</ul>

<p>
Doing this is safe:
</p>
<ul class="org-ul">
<li>Endpoints of P are not matched by M, but are matched in M‚Äô</li>
<li>Every other vertex is/remains incident on at most 1 edge of M‚Äô</li>
</ul>

<p>
Result is larger!
</p>
<ul class="org-ul">
<li>Majority of edges of P were not in M, but are in M‚Äô</li>
</ul>

<p>
Matching M in graph G is maximum if and only if there is no M-augmenting path in G. <i>(proof in slides and lecture notes)</i>
</p>

<p>
#+begin<sub>src</sub> python
Algorithm MaxMatching(G)
    M = {}
    while G has M-augmenting path P
    do exchange edges of P (augment M)
    return M
#+end<sub>src</sub> c
</p>
</div>
</div>
<div id="outline-container-orgdc76a21" class="outline-3">
<h3 id="orgdc76a21"><span class="section-number-3">8.2.</span> Matchings in bipartite graphs</h3>
<div class="outline-text-3" id="text-8-2">
<p>
<b>Bipartite graphs</b> are those whose vertices can be partitioned into two sets such that no edge of the graph has both its end-points in the same set.
</p>

<p>
Bipartite graph is a graph whose vertices can be divided into two disjoint and independent sets \(U\) and \(V\)
</p>
<ul class="org-ul">
<li>Every edge connects a vertex in \(U\) to one in \(V\).</li>
</ul>

<p>
Finding an *<a href="#orgda1084a">M-augmenting path*</a>:
</p>
<ul class="org-ul">
<li>Since the end points of an M-augmenting path must be unmatched, we start from an unmatched vertex.</li>
<li>If possible, we cross over to the opposite side using an edge not in M , and then come back to the same side using an edge in M.</li>
<li>We repeat the process until we either reach an unmatched vertex or conclude that no M-augmenting path exists..</li>
<li>An M -augmenting path has an odd number of edges.</li>
<li>So, if we start with an unmatched vertex on the left, we end in an unmatched vertex on the right and vice-versa.</li>
</ul>

<p>
To find an M-augmenting path, we use an <b>auxillary graph</b>:
</p>
<ul class="org-ul">
<li>direct the edges of the bipartite graph as follows:
<ul class="org-ul">
<li>If \(e\in M\), direct it from right to left.</li>
<li>If \(e \notin M\), direct it from left to right.</li>
</ul></li>
</ul>

<p>
Now we can do a DFS from every unmatched vertex on the left until we have found a path that ends in an unmatched vertex on the right.
</p>

<p>
We can avoid doing multiple DFS&rsquo;s by adding a source and sink vertex:
</p>
<ul class="org-ul">
<li>Add a &ldquo;source&rdquo; vertex and add arcs directed from the source to the unmatched vertices on the left.</li>
<li>We also add a ‚Äúsink‚Äù vertex and add arcs directed from the unmatched vertices on the right to the sink.</li>
<li>Now, we can run a DFS once to find a path from the source vertex to the sink. It takes \(O(n + m)\) time to find an M-augmenting path using this algorithm</li>
</ul>


<div id="org4c8d87f" class="figure">
<p><img src="Matchings_and_flow_1+2/2024-03-27_12-31-16_screenshot.png" alt="2024-03-27_12-31-16_screenshot.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-python">Algorithm FindBipMAugmenting(G, M)
    Make directed aux. graph <span style="color: #bb99ee;">for</span> G <span style="color: #bb99ee;">as</span> <span style="color: #bb99ee;">in</span> last slide
    Find source<span style="color: #88ccdd;">-</span>sink path P <span style="color: #bb99ee;">with</span> DFS <span style="color: #bb99ee;">in</span> aux. graph
    If path P found, then P <span style="color: #bb99ee;">is</span> a M<span style="color: #88ccdd;">-</span>augmenting path
    No path found? Then M <span style="color: #bb99ee;">is</span> maximum
</pre>
</div>

<p>
Running time: \(O(n+m)\)
</p>

<div class="org-src-container">
<pre class="src src-python">Algorithm BipMaxMatching(G)
   <span style="color: #ccccee;">M</span> <span style="color: #88ccdd;">=</span> {}
      <span style="color: #bb99ee;">while</span> P <span style="color: #88ccdd;">=</span> FindBipMAugmenting(G, M)
      do exchange edges of P (augment M)
   <span style="color: #bb99ee;">return</span> M
</pre>
</div>

<p>
Running time: \(O(n(n+m)) = O(nm)\)
</p>
</div>
</div>
<div id="outline-container-org13912af" class="outline-3">
<h3 id="org13912af"><span class="section-number-3">8.3.</span> Matchings of different types of graphs</h3>
<div class="outline-text-3" id="text-8-3">
<p>
<b>Bipartite graphs</b>
</p>

<p>
Hopcroft-karp algorithm: \(O(m\sqrt n)\)
</p>

<p>
<b>Weighted maximum matching</b>
</p>

<p>
From a graph with weighted edges \(w:E(G)\rightarrow \mathbb{R}\) find matching of largest possible total weight.
</p>

<p>
In bipartite graphs: make directed auxillary graph.
</p>
<ul class="org-ul">
<li>set \(length(e)= -w(e)\ if\ e \in E(G)\setminus M\)</li>
<li>set \(length(e)= w(e)\ if\ e \in M\)</li>
</ul>

<p>
Then find the shortest M-augmenting path.
</p>

<p>
Finding weigted maximmum matching in bipartite graph: Gabow-Tarjan [1988]: \(O(m\sqrt n \log (nW))\)
</p>

<p>
<b>Matching on general graphs</b>
</p>

<p>
Matchings on general paths is much harder, best time complexity is \(O(n^2m)\) Micali-Vazirani [1980], not taught in this course.
</p>

<p>
<b>Weighted general graphs</b>
</p>

<p>
Gabow [1990]: \(O(n (m + n \log n))\)
</p>
</div>
</div>
<div id="outline-container-orgf0f97aa" class="outline-3">
<h3 id="orgf0f97aa"><span class="section-number-3">8.4.</span> Stable matching / stable-marriage problem</h3>
<div class="outline-text-3" id="text-8-4">
<p>
We add information to each vertex: a ranking of the vertices in the other side.
</p>

<p>
That is, each vertex in L has an ordered list of all the vertices in R, and vice-versa.
</p>

<p>
The goal here is to match each vertex in L with a vertex in R in a stable way.
</p>

<p>
The <b>stable-marriage problem</b>:
</p>
<ul class="org-ul">
<li>comes from the notion of heterosexual marriage, viewing L as a set of women and R as a set of men.</li>
<li>Each woman ranks all the men in terms of desirability, and each man does the same with all the women.</li>
<li>The goal is to pair up women and men (a matching) so that if a woman and a man are not matched to each other, then at least one of them prefers their assigned partner.</li>
<li>A men and a woman are a <b>blocking pair</b> if they are not matched but each prefers the other over their assigned partner.
<ul class="org-ul">
<li>Such a pair prevents a a matching from being stable: <b>unstable</b></li>
</ul></li>
<li>A <b>stable</b> matching is a matching that has no blocking pairs</li>
<li>A stable matching is always possible</li>
</ul>

<p>
The Gale‚ÄìShapley algorithm: \(O(n^2)\)
</p>
</div>
</div>
</div>
<div id="outline-container-org8d4e057" class="outline-2">
<h2 id="org8d4e057"><span class="section-number-2">9.</span> Flow and cuts</h2>
<div class="outline-text-2" id="text-9">
</div>
<div id="outline-container-org708bd59" class="outline-3">
<h3 id="org708bd59"><span class="section-number-3">9.1.</span> Flow</h3>
<div class="outline-text-3" id="text-9-1">
<p>
A flow network
</p>
<ul class="org-ul">
<li>A directed graph \(G = (V, A)\)</li>
<li>For every arc \((u, v) \in A\),</li>
<li>There is a <b>capacity</b> denoted by \(c(u, v) \ge 0\).</li>
<li>There are two special vertices called the source and the sink such that all the arcs incident on the source are outgoing and all the arcs incident on the sink are incoming arcs.
<ul class="org-ul">
<li><b>Source:</b> \(s\) arcs incident on the source are outgoing</li>
<li><b>Sink:</b> \(t\) arcs incident on the sink are incoming</li>
</ul></li>
</ul>

<p>
If we want a network with multiple sources and sinks we add a <b>super sink</b> and a <b>super source</b> such that there are arcs from the super source to every source vertex and arcs from every sink vertex to the super sink.
</p>

<p>
<b>Flow:</b> A flow in any network \(G=(V,A)\) can be defined as a function \(f:A\rightarrow  \mathbb R\) such that it follows the following rules:
</p>
<ul class="org-ul">
<li><b>Capacity Constraint</b>: \(f (a) \le c(a)\), for all \(a\in A\)</li>
<li><b>Conservation of flow</b>: For every vertex v other than the source and the sink, the total flow going into the vertex equals the flow going out of it.
<ul class="org-ul">
<li>That is \(\sum_{u:(u,v)\in A}f((u,v))=\sum_{u:(v,u)\in A}f((v,u))\)</li>
</ul></li>
</ul>

<p>
<b>Value of flow</b>: The total value of flow in a given flow network
</p>
<ul class="org-ul">
<li>\(|f|=\sum_{u:(s,u)\in A}f((s,u))=\sum_{u:(u,t)\in A}f((u,t))\)</li>
<li>The total sum going from the source or the total sum going into the sink.</li>
</ul>

<p>
Flow can model many practical problems:
</p>
<ul class="org-ul">
<li>Assignment</li>
<li>Routing</li>
<li>Network robustness</li>
</ul>

<p>
Algorithms for finding a maximum value flow:
</p>
<ul class="org-ul">
<li>Ford-Fulkerson</li>
<li>Edmonds-Karp</li>
</ul>
</div>
</div>
<div id="outline-container-org12d85aa" class="outline-3">
<h3 id="org12d85aa"><span class="section-number-3">9.2.</span> Bipartite matching as flow</h3>
<div class="outline-text-3" id="text-9-2">
<p>
Finding a maximum matching in a bipartite graph can be modeled as a max-flow problem.
</p>

<p>
Given bipartite graph \(G=(U\cup V, E)\), to create the flow network \(G'\):
</p>
<ul class="org-ul">
<li>Direct all the edges in \(G\) from \(U\) to \(V\) and assign a capacity of \(1\) to each.</li>
<li>Add a source vertex \(s\) and add arcs of capacity \(1\) directed from \(s\) to each vertex in \(u\in U\)</li>
<li>Add a sink vertex \(t\) and add arcs of capacity \(1\) directed from each vertex in \(v\in V\) to \(t\).</li>
</ul>

<p>
Finding a maximum flow in \(G'\) amounts to finding a maximum matching in the bipartite graph G.
</p>

<p>
G has matching of size k if and only if G‚Ä≤ has an integer valued flow equal to k.
</p>

<p>
<i>Proof for above statement in lecture notes</i>
</p>

<p>
Algorithm for maximum bipartite matching:
</p>
<ul class="org-ul">
<li>Construct flow network</li>
<li>Find maximum flow from s to t with algorithm for maximum flow that yields integer flow; for example, Ford-Fulkerson</li>
<li>Translate flow back into a matching</li>
<li>Time: \(O(nm)\)</li>
</ul>
</div>
</div>
<div id="outline-container-org02e3bad" class="outline-3">
<h3 id="org02e3bad"><span class="section-number-3">9.3.</span> Generalized matching as flow</h3>
<div class="outline-text-3" id="text-9-3">
<ul class="org-ul">
<li>Given: bipartite graph \(G=(UV, E)\) with a capacity \(c(v)\) for every \(v\) in \(UV\)</li>
<li>Wanted: The largest subset of edges \(M \subseteq E\) such that every vertex \(v\) in \(U V\) is the endpoint of at most \(c(v)\) edges in \(M\)</li>
<li>Example application: U are workers who can do c(v) tasks. V are tasks with c(w)=1</li>
</ul>

<p>
Translate bipartite graph into flow network by appropriately assigning capacities to arcs.
</p>

<p>
The vertices also need to have capacities, this is modelled by translating the vertices to two vertices and a edge.
<img src="Flow_and_matchings/2024-03-28_21-50-25_screenshot.png" alt="2024-03-28_21-50-25_screenshot.png" />
</p>
</div>
</div>
<div id="outline-container-orgda691ef" class="outline-3">
<h3 id="orgda691ef"><span class="section-number-3">9.4.</span> The Ford-Fulkerson Algorithm</h3>
<div class="outline-text-3" id="text-9-4">
<p>
The Ford-Fulkerson Algorithm iteratively increases the value of flow. It starts with \(f(u,v)=0\) for all \(u,v\in V\), giving an initial flow of 0. Each iteration increases the flow value in G by finding an augmenting path in an associated residual network \(G_f\).
</p>

<p>
<b>Residual Network:</b>
</p>
<ul class="org-ul">
<li>Let \(f\) be a flow in the network \(G = (V, A)\) with capacities \(c\).</li>
<li>The residual network \(G_f\):</li>
<li>For every arc \((v,w)\) in A:
<ul class="org-ul">
<li>If \(f (v, w) < c(v, w)\), then \((v, w)\) is a forward arc in \(G_f\) of residual capacity
\(c_f (v, w) = c(v, w) - f (v, w)\)</li>
<li>If \(f (v, w) > 0\), then \((w, v)\) is a backward arc in \(G_f\) of residual capacity \(c_f (w, v) = f (v, w)\)</li>
</ul></li>
</ul>

<p>
The residual network gives us an overview of possible improvement/augmentation of flow. As long as there is an s - t path in the residual network, it is possible to augment the flow.
</p>

<p>
<b>Ford-Fulkerson Algorithm</b>
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #ccccee;">f</span>: f(<span style="color: #ccccee;">v</span>,<span style="color: #ccccee;">w</span>) <span style="color: #88ccdd;">=</span> <span style="color: #eeaa77;">0</span> <span style="color: #bb99ee;">for</span> <span style="color: #ee8899;">all</span> (v,w) <span style="color: #bb99ee;">in</span> A
Construct residual network G_f
<span style="color: #bb99ee;">while</span> There <span style="color: #bb99ee;">is</span> a path P <span style="color: #bb99ee;">from</span> s to t <span style="color: #bb99ee;">in</span> G_f do:
    <span style="color: #ccccee;">x</span> <span style="color: #88ccdd;">=</span> <span style="color: #ee8899;">min</span>{c_f(v,w)<span style="color: #88ccdd;">|</span>(v,w) <span style="color: #bb99ee;">in</span> P}
    <span style="color: #bb99ee;">for</span> (v,w) <span style="color: #bb99ee;">in</span> P do:
        <span style="color: #bb99ee;">if</span> (v,w) <span style="color: #bb99ee;">is</span> forward arc then:
            f(<span style="color: #ccccee;">v</span>,<span style="color: #ccccee;">w</span>) <span style="color: #88ccdd;">=</span> f(v,w) <span style="color: #88ccdd;">+</span> x
        <span style="color: #bb99ee;">else</span>:
            f(<span style="color: #ccccee;">v</span>,<span style="color: #ccccee;">w</span>) <span style="color: #88ccdd;">=</span> f(v,w) <span style="color: #88ccdd;">-</span> x
<span style="color: #bb99ee;">return</span> f
</pre>
</div>

<p>
Simplified: while there exists an augmenting path, augment the flow along p.
</p>

<p>
The edges of the augmenting path in \(G_f\) indicate on which edges in \(G\) to update the flow in order to increase the flow value.
</p>

<p>
Let \(f\) be the flow in \(G\) and \(g\) be the flow in \(G_f\). We define the <b>augmented flow</b> as:
</p>

\begin{equation}
(f+g)(u,v)=
\begin{cases}
f(u,v)+g(u,v)-g(v,u) & \text{if}(u,v) \in E(G)\\
0 & \text{otherwise} \\
\end{cases}
\end{equation}

<p>
The definition makes sense as we increase the flow on any edge of G by at most its residual capacity and decrease the flow on it by at most its flow value.
</p>


<p>
Proof of correctness of the algorithm in the lecture notes, probably worth it to read through.
</p>

<p>
Running time:
</p>
<ul class="org-ul">
<li>Residual network construction: \(O(n+m)\)
<ul class="org-ul">
<li>Only Arcs (u,v) with c(u,v)&gt;0 are relevant</li>
</ul></li>
<li>Finding path from s to t: DFS/BFS
<ul class="org-ul">
<li>\(O(n+m)\)</li>
</ul></li>
<li>Total running time depends on number of iterations</li>
<li>Could be the case that unlimited time is needed.</li>
</ul>
</div>
</div>
<div id="outline-container-org1e3ea2e" class="outline-3">
<h3 id="org1e3ea2e"><span class="section-number-3">9.5.</span> Cuts</h3>
<div class="outline-text-3" id="text-9-5">
<p>
An s-t-<b>cut</b> in a network \(G = (V, A)\) is a partition of the vertices into two sets \(S\) and \(T\), such that
</p>
<ul class="org-ul">
<li>\(S\cup T=V\)</li>
<li>\(S\cap T=\emptyset\)</li>
<li>\(s\in S\) and \(t\in T\)</li>
</ul>

<p>
The <b>capacity</b> of a cut \((S, T )\) is the sum of capacities of all the edges going from \(S\) to \(T\):
</p>
<ul class="org-ul">
<li>\(c(S, T)=\sum_{v\in S,w\in T:(v,w)\in A} c(v,w)\)</li>
</ul>

<p>
The flow over cut:
</p>
<ul class="org-ul">
<li>\(f(S, T)=\sum_{v\in S,w\in T:(v,w)\in A} f(v,w)\)</li>
</ul>

<p>
For every s-t cut \((S,T): f(S,T)\le c(S,T)\), from this it follows that \(|f| \le c(S,T)\).
</p>
<ul class="org-ul">
<li>It means that if we find a cut in G of capacity c, there cannot exist a flow in G of value greater than c.</li>
<li>Likewise, if we found a flow value \(c^*\) in G, we cannot find a cut of capacity less than \(c^*\).</li>
</ul>

<p>
The two above observations leads us to the following theorem:
</p>

<p>
<b>Max-Flow Min-Cut Theorem:</b> he maximum value of flow in a network G is equal to the capacity of a cut of smallest capacity.
</p>
</div>
<div id="outline-container-org6f448cf" class="outline-4">
<h4 id="org6f448cf"><span class="section-number-4">9.5.1.</span> Finding a mimimum cut</h4>
<div class="outline-text-4" id="text-9-5-1">
<p>
Given a direct graph \(G=(V,A)\), vertices s, t
</p>

<p>
What is the minimum number of arcs we have to remove from G so that no path from s to t remains.
</p>

<p>
Algorithm:
</p>
<ul class="org-ul">
<li>Assign all arcs capacity 1</li>
<li>Find maximum flow, for ex. using Ford-Fulk.</li>
<li>Determine S: all vertices reachable from s in \(G_f\)</li>
<li>Output set of arcs in G from S to V ‚Äì S</li>
</ul>

<p>
Not the best way as we will see next
</p>
</div>
</div>
</div>
<div id="outline-container-orga899c78" class="outline-3">
<h3 id="orga899c78"><span class="section-number-3">9.6.</span> Edmonds-Karp Algorithm</h3>
<div class="outline-text-3" id="text-9-6">
<p>
The ford-fulkerson algorithm could run for ever with non-integer output, and can also run for a long time even with integer valued capacities.
</p>

<div class="org-src-container">
<pre class="src src-python">procedure MaxFlow(G, c):
    <span style="color: #ccccee;">f</span>: f(<span style="color: #ccccee;">v</span>,<span style="color: #ccccee;">w</span>) <span style="color: #88ccdd;">=</span> <span style="color: #eeaa77;">0</span> <span style="color: #bb99ee;">for</span> <span style="color: #ee8899;">all</span> (v,w) <span style="color: #bb99ee;">in</span> A
    Construct residual network G_f
    Find the shortest path P <span style="color: #bb99ee;">from</span> s to t <span style="color: #bb99ee;">in</span> Gf using BFS
    <span style="color: #bb99ee;">if</span> P exists then
        <span style="color: #ccccee;">x</span> <span style="color: #88ccdd;">=</span> <span style="color: #ee8899;">min</span>{cf (v, w) <span style="color: #88ccdd;">|</span> (v, w) &#8712; P }
        <span style="color: #bb99ee;">for</span> (v, w) &#8712; P do
            <span style="color: #bb99ee;">if</span> (v, w) <span style="color: #bb99ee;">is</span> forward arc then
                f (<span style="color: #ccccee;">v</span>, <span style="color: #ccccee;">w</span>) <span style="color: #88ccdd;">=</span> f (v, w) <span style="color: #88ccdd;">+</span> x
            <span style="color: #bb99ee;">else</span>
                f (<span style="color: #ccccee;">v</span>, <span style="color: #ccccee;">w</span>) <span style="color: #88ccdd;">=</span> f (v, w) &#8722; x
</pre>
</div>

<p>
This algorithm has \(O(n*m^2)\) time.
</p>

<p>
Once again proof in lecture notes.
</p>
</div>
</div>
<div id="outline-container-org7544539" class="outline-3">
<h3 id="org7544539"><span class="section-number-3">9.7.</span> Other algorithms</h3>
<div class="outline-text-3" id="text-9-7">
<p>
Goldberg&rsquo;s push-relabel (preflow-push) algorithms:
</p>
<ul class="org-ul">
<li>Goldber-Tarjan[1986,1988]: \(O(nm\log \frac {n^2} m)\)</li>
</ul>

<p>
It can be solved in \(O(nm)\) time if the graph has a special structure.
</p>
</div>
</div>
</div>
<div id="outline-container-org681704b" class="outline-2">
<h2 id="org681704b"><span class="section-number-2">10.</span> Amortized analysis</h2>
<div class="outline-text-2" id="text-10">
<p>
<b>Amortized analysis:</b>
</p>
<ul class="org-ul">
<li>Find the amortized time complexity \(a^i\) for the i&rsquo;th operation such that \(\sum^n_{i=1}t_i \le\sum^n_{i=1}a_i \le f(n)\)</li>
<li>Reason about the total complexity instead of the complexity of a single operation</li>
</ul>

<p>
Why use amortized?
</p>
<ul class="org-ul">
<li>For maintaining data structures, many operations are involved
<ul class="org-ul">
<li>Some of the operations have small cost (time complexity), and some have large cost</li>
<li>In many cases, we can get better performance in the long-run than we can on a per- operation basis</li>
</ul></li>
<li>Other applications:
<ul class="org-ul">
<li>Data science: In long data processing pipelines, people care about the total time used more than the cost of a single operation</li>
<li>Bank loans scheme: Banks use amortization to calculate fixed payments for interest- bearing loans</li>
<li>Commercial: Some cell phone contracts allow rolling unused calling time from one one month into the next month</li>
</ul></li>
</ul>

<p>
Key Ideas of Amortized Analysis
</p>
<ul class="org-ul">
<li>It works when we consider a sequence of operations</li>
<li>There are cheap operations and expensive operations. If expensive operations are not possible to happen every time, we can average the large cost over long periods of time.</li>
<li>The total time complexity is not so high.</li>
<li>No probability involved, we are averaging over a sequence of operations, not the possible worst case running time of a single operations</li>
</ul>


<div id="org97329ff" class="figure">
<p><img src="Amortized_analysis/2024-03-31_21-30-05_screenshot.png" alt="2024-03-31_21-30-05_screenshot.png" />
</p>
</div>
</div>
<div id="outline-container-org2af4abf" class="outline-3">
<h3 id="org2af4abf"><span class="section-number-3">10.1.</span> Super stack</h3>
<div class="outline-text-3" id="text-10-1">
<p>
We will use a extended stack as an example for amortized analysis.
</p>

<p>
It supports 3 operations:
</p>
<ul class="org-ul">
<li><code>PUSH</code> \(O(1)\)</li>
<li><code>POP</code> \(O(1)\)</li>
<li><code>MULTI-POP(k)</code> \(O(min(k,n))\)</li>
</ul>

<p>
Assume we have n operations, the total time complexity would be \(O(n*n)\) (n multi pops).
</p>

<p>
However when we observe that <code>MULTI-POP</code> can never exceed the total number of items ever pushed into the stack. So the total time complexity of all =MULTI-POP=s cannot exceed \(O(n)\)
</p>

<p>
So the actual complexity of n operations here is \(O(n)\)
</p>
</div>
</div>
<div id="outline-container-org76f9865" class="outline-3">
<h3 id="org76f9865"><span class="section-number-3">10.2.</span> Aggregate method</h3>
<div class="outline-text-3" id="text-10-2">
<p>
<b>Aggregate method</b> is a method to find the amortized complexity of a operation.
</p>

<p>
\[\text{amortized time for each operation} = \frac{\text{total time complexity}}{\text{number of operations}}\]
</p>

<p>
Step 1: Calculate the total time complexity over the sequence of operations
</p>

<ul class="org-ul">
<li>You may need some parameters to help you calculate
<ul class="org-ul">
<li>There are PUSHs in the super stack example</li>
</ul></li>
</ul>

<p>
Step 2: Divide the total time complexity by the number of the operations. The result is the amortized cost per operation
</p>

<ul class="org-ul">
<li>Using aggregate method, every operation has the same amortized cost</li>
</ul>
</div>
<div id="outline-container-org25ec977" class="outline-4">
<h4 id="org25ec977"><span class="section-number-4">10.2.1.</span> Super stack example</h4>
<div class="outline-text-4" id="text-10-2-1">
<p>
Super stack under a sequence of PUSH/POP/MULTI-POP operations:
</p>
<ul class="org-ul">
<li>Assume there are \(x\) PUSH operations, the number of pops incurred by <code>POP</code> and <code>MULTI-POP</code> is at most \(x\). Therefore, the worst case total cost is at most \(x+x=2x\le 2n\)</li>
<li>The amortized time per operation \(\le \frac {2n} n =2\)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgc3267ba" class="outline-3">
<h3 id="orgc3267ba"><span class="section-number-3">10.3.</span> Accounting method</h3>
<div class="outline-text-3" id="text-10-3">
<p>
<b>Accounting method</b> is a method to find the amortized complexity of a operation.
</p>

<p>
This method comes from the observation that some operations are expensive and some are cheap.
</p>

<p>
We design a pricing scheme where we overestimate the cheap operations and underestimate the expensive operations such that at any moment, we are not underestimating the (current) total cost.
</p>

<ul class="org-ul">
<li>Instead of averaging the cost evenly on each of the operations, we design the ‚Äúprices‚Äù for different types of operations
<ul class="org-ul">
<li>The prices are the amortized cost of the operations</li>
<li>Different operations may have different amortized costs</li>
</ul></li>
<li>Saving:
<ul class="org-ul">
<li>Some operations have price higher than its actual cost: save credits</li>
<li>Some operations have price lower than its actual cost: withdraw credits</li>
<li>Always make sure that the saving is non-negative:  \(\sum^n_{i=1}a_i -\sum^n_{i=1}t_i\ge 0\)</li>
</ul></li>
</ul>

<p>
<b>Tips:</b>
Step 1: decide the amortized cost \(a_i\) for each (types) of the operations
</p>
<ul class="org-ul">
<li>You may have to make several guesses and check if any of them helps you to have low amortized cost</li>
</ul>
<p>
Step 2: Prove that your amortized cost is valid, that is, for all \(n, \sum^n_{i=1}a_i -\sum^n_{i=1}t_i\ge 0\)
</p>
<ul class="org-ul">
<li>As long as the inequality holds for all \(n\), the amortized cost is valid</li>
<li>The goal is to find the best ‚Äúprices‚Äù for the operations such that the total amortized cost is low while the inequality holds</li>
</ul>
</div>
<div id="outline-container-orgc126b19" class="outline-4">
<h4 id="orgc126b19"><span class="section-number-4">10.3.1.</span> Super stack example</h4>
<div class="outline-text-4" id="text-10-3-1">
<p>
A super stack supports operations PUSH, POP, and MULTI-POP.
</p>
<ul class="org-ul">
<li>PUSH(x): amortized cost \(a_i=2\) (actual cost \(t_i=1\))</li>
<li>POP(): amortized cost \(a_i=0\) (actual cost \(t_i=1\))</li>
<li>MULTI-POP(k): assign amortized cost \(a_i=0\) (actual cost \(t_i=k\))</li>
</ul>

<p>
We need to show the amortized costs are valid for the analysis:
</p>
<ul class="org-ul">
<li>starting with an empty stack, for any sequence of n operations, \(\sum^n_{i=1}a_i -\sum^n_{i=1}t_i\ge 0\)</li>
</ul>

<p>
We proof this using the following claim:
</p>
<ul class="org-ul">
<li>For any n \(\sum^n_{i=1}a_i -\sum^n_{i=1}t_i\ge s_n\)</li>
<li>Where \(s_i\) denotes the number of items in the stack after the i<sup>th</sup> operation.</li>
<li>We prove this claim using induction</li>
</ul>

<p>
Base case: When \(n=0\), both the amortized cost and the actual cost are 0. \(0\ge 0\)
</p>

<p>
<img src="Amortized_analysis/2024-03-31_21-52-49_screenshot.png" alt="2024-03-31_21-52-49_screenshot.png" />
<img src="Amortized_analysis/2024-03-31_21-54-05_screenshot.png" alt="2024-03-31_21-54-05_screenshot.png" />
</p>

<ul class="org-ul">
<li>We use accounting method to upper bound the total cost of Super Stack with n operations.</li>
<li>We first set the amortized cost of each operation and then prove by induction that the amortized cost is an upper bound of the actual cost at any point of the sequence of n operations.</li>
<li>If the next operation has an amortized cost lower than its actual cost, there must be enough ‚Äúsavings‚Äù from the previous operations to pay for the cost difference.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org5b66b54" class="outline-3">
<h3 id="org5b66b54"><span class="section-number-3">10.4.</span> Potential function</h3>
<div class="outline-text-3" id="text-10-4">
<p>
Amortized analysis is for data structures where expensive operations happen only when there are many cheap operations
</p>

<p>
There are risky situations that the next operation might be expensive
</p>
<ul class="org-ul">
<li>In Super stack: when there are many items in the stack, the next MULTI-POP( ) can be expensive</li>
<li>After these expensive operations, the data structure is safe again</li>
</ul>

<p>
Instead of associationg cost with particular operations or pieces of the data structure, we define a potential function on the entire data structure.
</p>
<ul class="org-ul">
<li>The potential function maps the <b>configuration</b> of the current data structure to a real number (the <b>potential</b>)</li>
<li>We aim to absorb the expensive cost by the <b>potential change</b>.</li>
</ul>

<p>
Let \(D_i\) denote our data structure configuration after ith the operation has been performed, and \(\Phi\) let  denote its potential.
</p>

<p>
The amortized cost of the i-th operation \(a_i=t_i+\Phi_i-\Phi_{i-1}\)
</p>

<p>
Where \(t_i\) is the actual cost of the i-th operation
</p>
<ul class="org-ul">
<li>A potential function is valid if for any i:</li>
<li>\(\sum^n_{i=1} a_i= \sum^n_{i=1} (t_i+\Phi_i-\Phi_{i-1})= (\sum^n_{i=1} t_i)+\Phi_n-\Phi_{0}\ge \sum^n_{i=1}t_i\)</li>
</ul>

<p>
We define a potential function which takes the current ‚Äúconfiguration‚Äù of the data structure as a parameter and maps it to a real number (potential).
</p>

<p>
The amortized cost of an operation is the sum of its actual cost and the potential change due to this operation. The potential function is carefully designed such that when the actual cost is high, the potential is decreased and can compensate for the high cost.
</p>

<p>
Examples in the slides, worth it to read through.
</p>
</div>
</div>
<div id="outline-container-org9ab8fdd" class="outline-3">
<h3 id="org9ab8fdd"><span class="section-number-3">10.5.</span> Fibonacci heaps</h3>
<div class="outline-text-3" id="text-10-5">
</div>
<div id="outline-container-org8af62e8" class="outline-4">
<h4 id="org8af62e8"><span class="section-number-4">10.5.1.</span> binary heap</h4>
<div class="outline-text-4" id="text-10-5-1">
<p>
A data structure to create a priority queue.
</p>
<ul class="org-ul">
<li><b>Shape property:</b>
<ul class="org-ul">
<li>All levels, except for thee deepest one, are fully filled</li>
<li>The deepest level is filled from left to right</li>
</ul></li>
<li><b>Min-heap ordering:</b> for every node, its children&rsquo;s key is greater than or equal to its key.</li>
</ul>


<div id="org2341d5f" class="figure">
<p><img src="Amortized_analysis/2024-04-01_12-12-18_screenshot.png" alt="2024-04-01_12-12-18_screenshot.png" />
</p>
</div>

<p>
Operations:
</p>
<ul class="org-ul">
<li><code>Find-Min</code>: \(O(1)\) time</li>
<li><code>Insert</code>: \(O(\log n)\) time
<ul class="org-ul">
<li>Start at the bottom, if the new item has a value smaller than its parent&rsquo;s value, swap the two values</li>
</ul></li>
<li><code>Extract-Min</code>: \(O(\log n)\) time
<ul class="org-ul">
<li>First delete the root, we move the last item to the. If the item moved to the root does not have a value smaller than its children, swap it with the smaller child. Do this recursively.</li>
</ul></li>
<li><code>Decrease-Key</code>: \(O(\log n)\) time</li>
<li><code>Union</code>: \(O(n)\) time</li>
</ul>
</div>
</div>
<div id="outline-container-orgddd6be5" class="outline-4">
<h4 id="orgddd6be5"><span class="section-number-4">10.5.2.</span> Fibonacci Heaps Structure</h4>
<div class="outline-text-4" id="text-10-5-2">
<p>
A <b>fibonacci heap</b> is a collection of <b>min-heap-ordered</b> component trees
</p>
<ul class="org-ul">
<li>There can be many trees inside one Fibonacci heap</li>
<li>Each tree satisfies the min-heap ordering</li>
<li>No need to rebuild everything when UNION is performed</li>
<li>Is &ldquo;lazy&rdquo;: usually structure is messy, is reorganizes when some expsenive operations happen.</li>
</ul>

<p>
Performance:
</p>
<ul class="org-ul">
<li>No good worst-case guarantee for any operation (except INSERT/ FIND-MIN)</li>
<li>Excellent amortized cost to perform each operation</li>
</ul>

<p>
Terminologies:
</p>
<ul class="org-ul">
<li><code>min(heap H)</code> the minimum value over all trees</li>
<li>Order of a node: the number of children of the node</li>
<li>Order of a tree: the order of the root node of the tree</li>
</ul>


<div id="orgf2c7646" class="figure">
<p><img src="Amortized_analysis/2024-04-01_13-50-23_screenshot.png" alt="2024-04-01_13-50-23_screenshot.png" />
</p>
</div>
</div>
</div>
<div id="outline-container-org2785a9c" class="outline-4">
<h4 id="org2785a9c"><span class="section-number-4">10.5.3.</span> Fibonacci heap operations</h4>
<div class="outline-text-4" id="text-10-5-3">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Operation</th>
<th scope="col" class="org-left">Actual  Cost</th>
<th scope="col" class="org-left">Amortized  Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">INSERT(heap H, key k)</td>
<td class="org-left">O(1)</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">FIND-MIN(heap H)</td>
<td class="org-left">O(1)</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">UNION(heap H1, heap H2)</td>
<td class="org-left">O(1)</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">DECREASE-KEY(heap H, node x, target key value k)</td>
<td class="org-left">O(number of cascading-cuts)</td>
<td class="org-left">O(1)</td>
</tr>

<tr>
<td class="org-left">EXTRACT-MIN(heap H)</td>
<td class="org-left">O(max degree + number of trees in the heap)</td>
<td class="org-left">O(log n)</td>
</tr>

<tr>
<td class="org-left">DELETE(heap H, node x)</td>
<td class="org-left">DECREASE-KEY +   EXTRACT-MIN</td>
<td class="org-left">O(log n)</td>
</tr>
</tbody>
</table>


<div id="orgb5e55a6" class="figure">
<p><img src="Amortized_analysis/2024-04-02_21-16-31_screenshot.png" alt="2024-04-02_21-16-31_screenshot.png" />
</p>
</div>
</div>
<ol class="org-ol">
<li><a id="org843f1c5"></a>INSERT<br />
<div class="outline-text-5" id="text-10-5-3-1">
<div class="org-src-container">
<pre class="src src-c"><span style="color: #88aaee;">INSERT</span> (<span style="color: #eeddaa;">heap</span> <span style="color: #ccccee;">H</span>, <span style="color: #eeddaa;">key</span> <span style="color: #ccccee;">k</span>)
{
    Add a node with key
    If k &lt; min(H)
      min(H) &lt;- k
}
</pre>
</div>
<p>
Example insert 0:
</p>


<div id="org7a202da" class="figure">
<p><img src="Amortized_analysis/2024-04-01_14-29-06_screenshot.png" alt="2024-04-01_14-29-06_screenshot.png" />
</p>
</div>


<div id="org3efbc56" class="figure">
<p><img src="Amortized_analysis/2024-04-01_14-31-00_screenshot.png" alt="2024-04-01_14-31-00_screenshot.png" />
</p>
</div>
</div>
</li>
<li><a id="orgbe173d1"></a>FIND-MIN<br />
<div class="outline-text-5" id="text-10-5-3-2">
<p>
FIN     D-MIN (heap H): return the minimum value of the keys in the heap H
</p>

<p>
Simply return the value pointed to by the Min pointer
</p>
</div>
</li>
<li><a id="org00409ac"></a>UNION<br />
<div class="outline-text-5" id="text-10-5-3-3">
<p>
UNION heap \(H_1\), heap \(H_2\): union two heaps \(H_1\) and \(H_2\)
</p>

<div class="org-src-container">
<pre class="src src-c"><span style="color: #88aaee;">UNION</span>(<span style="color: #eeddaa;">heap</span> <span style="color: #ccccee;">H1</span>, <span style="color: #eeddaa;">heap</span> <span style="color: #ccccee;">H1</span>)
{
    <span style="color: #eeaa77;">1</span>. Put all the elements in both heaps together to the new heap H
    <span style="color: #eeaa77;">2</span>. Update min(H)
}
</pre>
</div>
</div>
</li>
<li><a id="org4f502c5"></a>DECREASE-KEY<br />
<div class="outline-text-5" id="text-10-5-3-4">
<p>
DECREASE-KEY(heap H, node x, target<sub>key</sub> k): given a specified node x (by a pointer), lower its key to the value k
</p>
<div class="org-src-container">
<pre class="src src-c">DECREASE-KEY(<span style="color: #eeddaa;">heap</span> <span style="color: #ccccee;">H</span>, <span style="color: #eeddaa;">node</span> <span style="color: #ccccee;">x</span>, target_key k){
    Change the key value x of to k
    If k is smaller than the key of x&#8217;s parent p
        Cut x from p
        CASCADING-CUT(H, p)
    <span style="color: #eeddaa;">Update</span> <span style="color: #88aaee;">min</span>(H)}

CASCADING-CUT(<span style="color: #eeddaa;">heap</span> <span style="color: #ccccee;">H</span>, node x){
    If x is not marked
        Mark x
    Else
        Cut x from its <span style="color: #eeddaa;">parent</span> <span style="color: #ccccee;">p</span>, <span style="color: #ccccee;">unmark</span> x
        CASCADING-CUT( H, p)}
</pre>
</div>

<p>
Whithout <code>CASCADING-CUT</code>, we could en up with a loose tree: larger order but there are only a few nodes in a tree.
</p>
<ul class="org-ul">
<li>This way a node can only lose on child before being cut.</li>
<li>The minimum number of nodes in a tree of order k is \(F_{k+2}\ge \phi^k \Leftrightarrow\) any tree with n nodes has order at most \(O(log_\phi n)\)</li>
<li>\(\phi=\) gold ratio 1.618</li>
</ul>

<p>
Example: with target key 3
</p>


<div id="org2837e50" class="figure">
<p><img src="Amortized_analysis/2024-04-01_15-10-59_screenshot.png" alt="2024-04-01_15-10-59_screenshot.png" />
</p>
</div>

<p>
5 is changed to 3 and cut from the three put in the top level.
</p>


<div id="org59b85a5" class="figure">
<p><img src="Amortized_analysis/2024-04-01_15-13-47_screenshot.png" alt="2024-04-01_15-13-47_screenshot.png" />
</p>
</div>

<p>
Now example with target 4 and node x
</p>


<div id="org73a462e" class="figure">
<p><img src="Amortized_analysis/2024-04-01_15-15-03_screenshot.png" alt="2024-04-01_15-15-03_screenshot.png" />
</p>
</div>

<p>
4 gets cut from the tree
</p>


<div id="org2c275f1" class="figure">
<p><img src="Amortized_analysis/2024-04-01_15-16-09_screenshot.png" alt="2024-04-01_15-16-09_screenshot.png" />
</p>
</div>

<p>
Because p was marked it is cut and unmarked, and cascading cut is called on its parent, which then get marked.
<img src="Amortized_analysis/2024-04-01_15-17-42_screenshot.png" alt="2024-04-01_15-17-42_screenshot.png" />
</p>
</div>
</li>
<li><a id="org53de8e9"></a>EXTRACT-MIN<br />
<div class="outline-text-5" id="text-10-5-3-5">
<p>
<code>EXTRACT-MIN(heap H)</code>: return the minimum value and remove it from H
</p>

<p>
An expensive operation because it has to go through te roots of all other trees and find the minimum. Because it is expensive anyway we add reorganize the datastructure to be more efficient later.
</p>

<div class="org-src-container">
<pre class="src src-c">EXTRACT-MIN(heap H){
    Delete the min node y from H
    For each child z of y
        The subtree rooted on z is a new tree <span style="color: #eeddaa;">in</span> <span style="color: #ccccee;">H</span>, <span style="color: #ccccee;">unmark</span> z
    Consolidate(H)
    <span style="color: #eeddaa;">Update</span> <span style="color: #88aaee;">min</span>(H)
}

<span style="color: #88aaee;">Consolidate</span>(<span style="color: #eeddaa;">heap</span> <span style="color: #ccccee;">H</span>){
    <span style="color: #eeddaa;">For</span> <span style="color: #ccccee;">i</span> = <span style="color: #eeaa77;">0</span> to max-degree(h)
        Pair the trees with order i and make the one
        with larger root-key value a new child of the
        other one
}
</pre>
</div>

<p>
Consolidate combines trees that are of the same order together.
</p>

<p>
The two left most trees will be consolidated
<img src="Amortized_analysis/2024-04-02_20-49-36_screenshot.png" alt="2024-04-02_20-49-36_screenshot.png" />
</p>

<p>
Result:
<img src="Amortized_analysis/2024-04-02_20-49-50_screenshot.png" alt="2024-04-02_20-49-50_screenshot.png" />
</p>

<p>
Actual cost: \(O(\text{max degree}+{\#trees})\)
</p>
</div>
</li>
<li><a id="org66701da"></a>DELETE<br />
<div class="outline-text-5" id="text-10-5-3-6">
<p>
We first decrease the key value of the target node to the minimuym vlaue, and then call <code>EXTRACT-MIN</code> on it.
</p>

<div class="org-src-container">
<pre class="src src-c">DECREASE-KEY(H,x,&#8722;&#8734;)
EXTRACT-MIN(H)
</pre>
</div>
</div>
</li>
</ol>
</div>
<div id="outline-container-orgb72db7a" class="outline-4">
<h4 id="orgb72db7a"><span class="section-number-4">10.5.4.</span> Amortized analysis of Fibonacci heaps</h4>
<div class="outline-text-4" id="text-10-5-4">

<div id="org790db50" class="figure">
<p><img src="Amortized_analysis/2024-04-02_21-16-31_screenshot.png" alt="2024-04-02_21-16-31_screenshot.png" />
</p>
</div>

<p>
Without amortized analysis the fibonacci heap does not make sense, however with it the time complexitys are quite good.
</p>

<p>
In the lecture notes it is analysed using <a href="#org5b66b54">potential functions.</a>
</p>

<p>
First we define some things:
</p>
<ul class="org-ul">
<li>\(b_i\) number of trees after the i-th operation</li>
<li>\(m_i\) number of marked nodes after the i-th operation</li>
<li>Potential function \(\Phi _i\) after the i-th operation is \(O(b_i)+O(m_i)\)</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="orgbf17e18"></a>DECREASE-KEY analysis<br />
<div class="outline-text-5" id="text-10-5-4-1">
<p>
Recall that decrease-key takes \(O(c)\) time, where c is the number of cuttings incurred by the cascading cut.
</p>

<p>
After decrease-key the \(c\) cuttings create \(c\) new trees, and the \(c\) new roots are unmarked. It marks one node.
</p>

<p>
So \(b_i=b_{i-1}+c\) and \(m_i\le m_{i-1} -c+1\).
</p>

<p>
So the amortized cost is \(t_i+ \Phi_i-\Phi_{i-1}=O(c)+O(c)+O(-c+1)=O(1)\)
</p>
</div>
</li>
<li><a id="orgb92cea1"></a>EXTRACT-MIN analysis<br />
<div class="outline-text-5" id="text-10-5-4-2">
<p>
EXTRACT-MIN takes \(O(\text{max degree}+\text{\#trees})\) time.
</p>

<p>
After consolidation there are most Max-degree + 1 trees left: \(b_i\le \text{max degree} +1\).
</p>

<p>
The number of marked nodes is still the same.
</p>

<p>
So the amortized cost is \(t_i+ \Phi_i-\Phi_{i-1} = O(\text{max degree}+b_i) + O(\text{max degree}+1) - O(b_i)=O(\text{max degree})\)
</p>

<p>
Now we need to find if we can bound max-degree.
</p>

<p>
Right after consolidation an order-k tree has \(2^k\) nodes.
</p>

<p>
The marking of nodes makes sure that any node loses at most one child. Therefore an order-k tree has at least \(F_{k+2}\) nodes. Where \(F_i\) is the i-th fibonacci number.
</p>

<p>
So an order-k tree has at least \(F_{k+2}\ge \phi^k\) nodes, where \(\phi\) is the golden ratio. In other words, a tree with \(n\) nodes has an order of at mos \(O(\log_\phi n)\).
</p>

<p>
So the amortized extract min cost is \(O(\log n)\)
</p>
</div>
</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgb21b9b3" class="outline-2">
<h2 id="orgb21b9b3"><span class="section-number-2">11.</span> Minimum spanning trees and Union find</h2>
<div class="outline-text-2" id="text-11">
<p>
Example minimum spanning tree: connect the cities with as little cost as possible
</p>


<div id="org752bb21" class="figure">
<p><img src="minimum_spanning_trees_and_Union_find/2024-04-05_08-45-15_screenshot.png" alt="2024-04-05_08-45-15_screenshot.png" />
</p>
</div>

<p>
Terminologies:
</p>
<ul class="org-ul">
<li><b>Span:</b> a subset of edges that connects al the vertices</li>
<li><b>Spanning tree:</b> the subset of edges is acyclic and connects all the vertices</li>
<li><b>Minimum spanning tree:</b> the spanning tree \(T\) such that total weight \(w(T)=\sum_{(u,v)\in F}w(u,v)\)
<ul class="org-ul">
<li>There can be multiple minimum spanning tree in a graph</li>
</ul></li>
</ul>

<p>
If all edge weights in the given graph are different, the minimum spanning tree is unique. Throughout this lecture we assume the edge weights are unique.
</p>
</div>
<div id="outline-container-org131f47d" class="outline-3">
<h3 id="org131f47d"><span class="section-number-3">11.1.</span> Generic MST algorithm</h3>
<div class="outline-text-3" id="text-11-1">
<p>
All of the mst algorithms work like this:
</p>

<ul class="org-ul">
<li>The generic MST algorithm maintains an acyclic subgraph \(F\) of the input graph \(G\)</li>
<li>At all times \(F\), is a subgraph of the final minimum spanning tree of \(G\)</li>
<li>Initially, \(F\) consists of \(V\) singleton trees</li>
<li>The generic algorithm connected trees in \(F\) by adding certain edges between them, and make sure that these added edges are safe.
<ul class="org-ul">
<li>After incuding these edges the new Forest \(F\) is still a subgraph of the final minimum spanning tree of G</li>
</ul></li>
</ul>

<div class="org-src-container">
<pre class="src src-python">GENERIC<span style="color: #88ccdd;">-</span>MST(G)
F &#8592; &#981;
<span style="color: #bb99ee;">while</span> F does <span style="color: #bb99ee;">not</span> form a spanning tree
    find an edge (u,v) that <span style="color: #bb99ee;">is</span> safe <span style="color: #bb99ee;">for</span> F
    F &#8592; F &#8746; {(u, v)}
    <span style="color: #bb99ee;">return</span> F
</pre>
</div>

<div id="org8e9b755" class="figure">
<p><img src="minimum_spanning_trees_and_Union_find/2024-04-05_08-58-49_screenshot.png" alt="2024-04-05_08-58-49_screenshot.png" />
</p>
</div>


<div id="orga565479" class="figure">
<p><img src="minimum_spanning_trees_and_Union_find/2024-04-05_08-59-19_screenshot.png" alt="2024-04-05_08-59-19_screenshot.png" />
</p>
</div>
</div>
</div>
<div id="outline-container-orgf5a49f6" class="outline-3">
<h3 id="orgf5a49f6"><span class="section-number-3">11.2.</span> Light Edges</h3>
<div class="outline-text-3" id="text-11-2">
<p>
How do we now if an edge is safe to add to a graph?
</p>
<ul class="org-ul">
<li>An edge is safe when it belongs to the minimum spanning tree.</li>
<li>We call that a <b>light edge</b></li>
</ul>

<p>
At any moment during the generic algorithm, the subgraph F has one or more connected components. A light edge for a component \(C\) is an edge \((u, v)\) such that there is exactly one endpoint in \(C\) and has the minimum weight. In the following, we show that adding a light edge is safe.
</p>


<div id="orgbf256c0" class="figure">
<p><img src="minimum_spanning_trees_and_Union_find/2024-04-06_11-34-38_screenshot.png" alt="2024-04-06_11-34-38_screenshot.png" />
</p>
</div>
</div>
</div>
<div id="outline-container-orgb3a7303" class="outline-3">
<h3 id="orgb3a7303"><span class="section-number-3">11.3.</span> Boruvka&rsquo;s algorithm</h3>
<div class="outline-text-3" id="text-11-3">
<p>
<b>Boruvka&rsquo;s algorit</b> is quite simple:
</p>
<div class="org-src-container">
<pre class="src src-c"><span style="color: #bb99ee;">while</span> F is not a spanning tree <span style="color: #bb99ee;">do</span>
    Add all light edges
</pre>
</div>

<ul class="org-ul">
<li>To maintain the information about components, we can use an array called comp. The entry comp[i] keeps the information of which component the vertex i belongs to.</li>
<li>Initially, each component is a singleton.</li>
<li>In each round, the algorithm should check each edge if it is a light edge by checking the comp array in O(|E|) time.</li>
<li>If an edge is a light edge for some 2 component, it is bought.</li>
<li>After buying a light edge, the algorithm runs a DFS on the graph \((V, F )\) and updates the component information in \(O(|V | + |F |) = O(|V |)\) time.
<ul class="org-ul">
<li>Add the vertices to the update component</li>
</ul></li>
<li>In each round, the total time complexity is \(O(|V |+|E|)\).</li>
<li>There are at most \(O(log |V |)\) rounds since after each round, the components are matched at least in pairs.</li>
<li>Therefore, total time complexity is \(O(|E| log |V |)\).</li>
</ul>
</div>
</div>
<div id="outline-container-org5d9c1f6" class="outline-3">
<h3 id="org5d9c1f6"><span class="section-number-3">11.4.</span> Prim&rsquo;s algorithm</h3>
<div class="outline-text-3" id="text-11-4">
<p>
<b>Prim‚Äôs algorithm</b> starts at an arbitrary vertex and repeatedly adds its light edge.
</p>

<p>
So just repeatedly add the outgoing edge with the lowest weight that connects a new vertex.
</p>
<div class="org-src-container">
<pre class="src src-c">Start at a singleton T
Repeatedly adding the light edge of T to F
</pre>
</div>

<p>
We keep all the outgoing edges from T in a priority queue Q, acoording to the edge weights.
</p>

<p>
In every of the \(|E|\) rounds:
</p>
<ul class="org-ul">
<li>If the lightest edge in Q has exactly one ednpoint in T, buy it and include the neighbour vertex</li>
<li>Add all new outgoing edges to Q</li>
</ul>

<p>
Time complexity:
</p>
<ul class="org-ul">
<li>Each edge is extracted from Q once: \(O(log|E|)=O(log|V|)\) for each edge</li>
<li>Each edge is inserted in Q once: \(O(log|E|)=O(log|V|)\) for each edge</li>
<li>Total complexity: \(O(|E|log|V|+|E|log|V|)=O(|E|log|V|)\)</li>
</ul>

<p>
We can also use a fibonacci heap to implement the priority queue.
</p>
<ul class="org-ul">
<li>Now we keep the vertices in the priority queue instead of the edges, where the value of v is the minimum edge weight between v and the evolving tree T (\(\infty\) if there is no such edge)</li>
<li>In every of the \(|V|\) rounds, ExtractMin(Q), buy the corresponding edge, and decrease the value of some neighboring vertices</li>
</ul>

<p>
Time complexity:
</p>
<ul class="org-ul">
<li>\(O(|V|)\) times ExtracTMin amortized \(O(\log |V|)\) time</li>
<li>\(O(|E|)\) times DecreaseKey amortized \(O(1)\) time</li>
<li>Total time complexity: \(O(|E|+|V|\log |V|)\)</li>
</ul>
</div>
</div>
<div id="outline-container-org44a892a" class="outline-3">
<h3 id="org44a892a"><span class="section-number-3">11.5.</span> Disjoint Set Union-Find</h3>
<div class="outline-text-3" id="text-11-5">
<p>
This data structure will be important to the next minimum spanning tree algorithm.
</p>

<p>
Given a universe of elements \(U=\{a,b,c,...\}\)
</p>

<p>
At any time, maintain a collection \(\mathbb S=\{S_1,S_2,...,S_k\}\) of disjoint sets.
</p>

<p>
This datastructure supports the following operations:
</p>
<ul class="org-ul">
<li><code>Find(e)</code> return the set name which the element <code>e</code> belongs to</li>
<li><code>Union(i,j)</code> if the elements i and j are not in the same set, merge these two sets.</li>
</ul>

<p>
There are two ways to implement this datastructure
</p>
<ul class="org-ul">
<li>Using linked lists</li>
<li>Using a forest</li>
</ul>
</div>
<div id="outline-container-orgb60aa50" class="outline-4">
<h4 id="orgb60aa50"><span class="section-number-4">11.5.1.</span> Linked lists</h4>
<div class="outline-text-4" id="text-11-5-1">

<div id="org555a692" class="figure">
<p><img src="minimum_spanning_trees_and_Union_find/2024-04-06_17-01-03_screenshot.png" alt="2024-04-06_17-01-03_screenshot.png" />
</p>
</div>

<p>
<code>find</code>: \(O(1)\)
</p>

<p>
<img src="minimum_spanning_trees_and_Union_find/2024-04-06_17-02-40_screenshot.png" alt="2024-04-06_17-02-40_screenshot.png" />
<img src="minimum_spanning_trees_and_Union_find/2024-04-06_17-02-57_screenshot.png" alt="2024-04-06_17-02-57_screenshot.png" />
</p>


<p>
<code>Union</code>: \(O(n)\), with n: number of items
</p>
</div>
</div>
<div id="outline-container-orgc351cc6" class="outline-4">
<h4 id="orgc351cc6"><span class="section-number-4">11.5.2.</span> Forest</h4>
<div class="outline-text-4" id="text-11-5-2">
<p>
For each of the sets there is a tree.
</p>

<p>
When we Find an element, it should return the root of the tree
</p>

<p>
When union, always link root of the smaller tree to the root of the larger tree
</p>
<ul class="org-ul">
<li>Doing it this way bounds the max hight of the tree to: \(H_max=O(\log n)\)</li>
<li>Size is height of the tree in this case.</li>
</ul>


<div id="org3a6537a" class="figure">
<p><img src="minimum_spanning_trees_and_Union_find/2024-04-06_17-15-15_screenshot.png" alt="2024-04-06_17-15-15_screenshot.png" />
</p>
</div>

<p>
<code>Find</code>: \(O(H_{max})=O(\log n)\)
</p>


<div id="orgd05d213" class="figure">
<p><img src="minimum_spanning_trees_and_Union_find/2024-04-06_17-16-06_screenshot.png" alt="2024-04-06_17-16-06_screenshot.png" />
</p>
</div>

<p>
<code>Union</code>: \(O(H_{max})=O(\log n)\)
</p>
<ul class="org-ul">
<li>Two finds and a link</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgc7fd750" class="outline-3">
<h3 id="orgc7fd750"><span class="section-number-3">11.6.</span> Kruskal&rsquo;s algorithm</h3>
<div class="outline-text-3" id="text-11-6">
<div class="org-src-container">
<pre class="src src-c"><span style="color: #88aaee;">Kruskal</span>(G):
  Scan all edges by increasing weight
  <span style="color: #bb99ee;">if</span> an edge is light <span style="color: #bb99ee;">for</span> some component, add it to F
</pre>
</div>

<ul class="org-ul">
<li>First sort edges by increasing weight: \(O( | E | \log | E | ) = O( | E | \log | V | )\)</li>
<li>For each of the \(O(|E|)\) rounds
<ul class="org-ul">
<li>If the edge connects two different components, buy it \(O(\log |V|)\)
<ul class="org-ul">
<li>The two components are merged into one
<ul class="org-ul">
<li>This can be done using an array or linked lists, but this is inefficient: total \(O(|V|^2)\)</li>
<li>We use a forest where we always merge the smaller one to the larger one: total \(O(|V|log|V|)\)</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org0ddce7d" class="outline-3">
<h3 id="org0ddce7d"><span class="section-number-3">11.7.</span> Graphs with repeated weights</h3>
<div class="outline-text-3" id="text-11-7">
<p>
The algorithms described in this lecture also work for graphs where some edges have equal weights, as long as we have a consistent method for breaking ties when choosing the light edge.
</p>

<p>
<i>For example:</i>
<img src="minimum_spanning_trees_and_Union_find/2024-04-06_17-21-48_screenshot.png" alt="2024-04-06_17-21-48_screenshot.png" />
</p>
</div>
</div>
</div>
<div id="outline-container-org1d57d33" class="outline-2">
<h2 id="org1d57d33"><span class="section-number-2">12.</span> NP-completeness</h2>
<div class="outline-text-2" id="text-12">
<p>
<b>Decision problems:</b> solution is a yes/no answer.
</p>
<ul class="org-ul">
<li>Example subset-sum: Given an set of integers, is there a sbuset such that the sum of the elements in T is equal to t</li>
</ul>

<p>
<b>Optimization problems:</b> minimize or maximize some objective
</p>
</div>
<div id="outline-container-orgf85c468" class="outline-3">
<h3 id="orgf85c468"><span class="section-number-3">12.1.</span> P and NP</h3>
<div class="outline-text-3" id="text-12-1">
<p>
We define <b>input size</b> as the number of bits needed to encode it.
</p>

<p>
Given an algorithm, its <b>time complexity</b> is a function f where f (n) is the maximum number of steps that the algorithm takes on any input of length n.
</p>
</div>
<div id="outline-container-orge4d1aa1" class="outline-4">
<h4 id="orge4d1aa1"><span class="section-number-4">12.1.1.</span> The class P</h4>
<div class="outline-text-4" id="text-12-1-1">
<p>
The class <b>P</b> is the set of decision problems that can be solved in polynomial time.
</p>

<p>
To show that a problem is in P, on should design an algorithm that correctly solves the problem and show that this algorithm finishes in time that polynomial in the input length for any input.
</p>

<p>
The problems in class p are restricted to decisions problems. We can make an <b>equivalent decision version of optimization problems</b> by introducing an extra parameter as a threshold of the object.
</p>
</div>
</div>
<div id="outline-container-orgf5d55e5" class="outline-4">
<h4 id="orgf5d55e5"><span class="section-number-4">12.1.2.</span> The class NP</h4>
<div class="outline-text-4" id="text-12-1-2">
<p>
For some problems, solving them directly is difficult. But if someone somehow discovered the solution it is easy to verify.
</p>

<p>
The concept of <b>verify</b> is to use an extra piece of information to check if the answer to a problem instance is yes.
</p>
<ul class="org-ul">
<li>Called a <b>certificate</b> or <b>proof</b></li>
</ul>

<p>
If there exists a polynomial-time algorithm that can verify any yes-instance of a problem, its <b>polynomial time verifiable</b>.
</p>

<p>
The class <b>NP</b> is the set of decision problems that can be verified in polynomial time.
</p>

<p>
To show that a problem is in NP, one should design a polynomial-time algorithm that correctly verifies any yes-instance using a certificate, where the certificate needs to be defined by the prover. The proof consists of three parts:
</p>
<ol class="org-ol">
<li>Show that for every yes-instance of A, there is a certificate c.</li>
<li>Design a verifier algorithm that answers to the instance is yes using c.</li>
<li>Show that this verifier algorithm can be run in polynomial time in the input length.</li>
</ol>

<p>
Example proof in lecture slides.
</p>
</div>
</div>
</div>
<div id="outline-container-orgae1e95d" class="outline-3">
<h3 id="orgae1e95d"><span class="section-number-3">12.2.</span> Polynomial-time reduction and NP-hardness</h3>
<div class="outline-text-3" id="text-12-2">
<p>
Besides solving the problems directly, we can also show that a problem is solvable by reducing it to another problem. A <b>reduction</b> is a way of converting one problem to another such that a solution to the second problem can be used to solve the first problem. That is, if problem A reduces to problem B, we can use a solution to B to solve A.
</p>

<p>
A problem \(A\) is polynomial-time reducible to problem B, written \(A \le_P B\), if a polynomial-time computable function \(f\) exists, where for every instance \(w\) of \(A\), \(w\) is a yes-instance of \(A\) if and only if \(f (w)\) is a yes-instance of \(B\). The function \(f\) is called the polynomial-time reduction of \(A\) to \(B\).
</p>
<ul class="org-ul">
<li>If A reduces to problem B, B is not easier than A.</li>
<li><p>
If problem A is polynomial-time reducible to problem B and problem B is polynomial-time solvable, then A can be solved in polynomial-time.
</p>


<div id="org72acf1c" class="figure">
<p><img src="NP-completeness/2024-04-05_21-51-29_screenshot.png" alt="2024-04-05_21-51-29_screenshot.png" />
</p>
</div></li>
</ul>

<p>
A valid reduction should guarantee that after transforming the input of problem A, w, to an input of problem B, f(w), w is a yes-instance of A if and only if f(w) is a yes-instance of B.
</p>

<p>
To show that a polynomial-time reduction from A to B is valid, for any input w to A, we should prove the following three things:
</p>
<ul class="org-ul">
<li>The function f can be calculated in polynomial-time in the length of w.</li>
<li>If f (w) is a yes-instance of problem B, w is a yes-instance of problem A.</li>
<li>If f (w) is a no-instance of problem B, w is a no-instance of problem A
<ul class="org-ul">
<li>This is item is equivalent to If w is a yes-instance of problem A, f (w) is a yes-instance of problem B.</li>
</ul></li>
</ul>

<p>
A problem is <b>NP-hard</b> if all problems in NP are polynomial-time reducible to it.
</p>
</div>
</div>
<div id="outline-container-orgadb9354" class="outline-3">
<h3 id="orgadb9354"><span class="section-number-3">12.3.</span> NP-Completeness</h3>
<div class="outline-text-3" id="text-12-3">
<p>
There are a few problems in NP that if they can be solved in polynomial time, then \(P=NP\).
</p>

<p>
These problems are called <b>NP-Complete</b>: problem is in NP and NP-Hard
</p>
<ul class="org-ul">
<li>Individual complexity is related to that of the entier NP class.</li>
<li>If an NP-Complete problem is proved to be polynomial-time solvable, all problems in NP are polynomial-time solvable.</li>
<li>On the contrary, if there is any problem in NP that needs more than polynomial time to solve, it must be one of the NP-complete problems.</li>
</ul>

<p>
NP-Completeness proof.
</p>
<ul class="org-ul">
<li>To show that a problem B is NP-complete, we have to show that it is in NP and NP-hard.</li>
<li>By the definition of NP-hardness, we have to show that every problem in NP is polynomial-time reducible to B, which is difficult.</li>
<li>We can instead show that there exists some NP-complete problem A that reduces to B in polynomial time.</li>
<li>Since A is NP-complete, it is NP-hard, and every problem in NP can be reduced to A in polynomial time.</li>
<li>Therefore, every problem in NP can be polynomial-time reduced to A first and then polynomial-time reduced to B.</li>
<li>That is, there is a polynomial-time reduction from any problem in NP to B.</li>
</ul>

<p>
<i>Example proofs in lecture notes, recommended to look at it.</i>
</p>
</div>
</div>
</div>
<div id="outline-container-org0fe8dbe" class="outline-2">
<h2 id="org0fe8dbe"><span class="section-number-2">13.</span> Approximation Algorithms</h2>
<div class="outline-text-2" id="text-13">
<p>
How do we deal with an NP-complete problem?
</p>
<ol class="org-ol">
<li>Exact exponential time algorithm: very slow</li>
<li>Polynomial time solvable for some special cases?</li>
<li>Fixed parameter algorithms</li>
<li>Approximation algorithms</li>
</ol>

<p>
<b>Approximation algorithms:</b> Instead of finding the exact solution we find near-optimal solutions efficiently.
</p>
<ul class="org-ul">
<li>Spend polynomial time to get a solution with some guarantee that it won‚Äôt be too much worse than the real optimal solution</li>
</ul>

<p>
We use <b>approximation ratio</b> measure how ‚Äúfar‚Äù the solution of the approximation algorithm \(ALG(I)\) is from the optimal solution \(OPT(I)\)
</p>
<ul class="org-ul">
<li>\(ALG(I)\): the &ldquo;cost&rdquo; of the approximation algorithm on input I</li>
<li>\(OPT(I)\): the &ldquo;cost&rdquo; of the optimal algorithm on input I</li>
<li>The definition of cost here is confusing, this isn&rsquo;t referring to running time of the algorithm but of how optimal the solution is
<ul class="org-ul">
<li>Each potential solution has a positive cost, depending on the problem we want to minimize or maximize the cost.</li>
</ul></li>
<li><b>Minimization problems</b>: the <b>approximation ratio</b> of the algorithm is \(\max_I\frac{ALG(I)}{OPT(I)}\) for all instance \(I\)</li>
<li><b>Maximization problems</b>: the <b>approximation ratio</b> of the algorithm is \(\max_I\frac{OPT(I)}{ALG(I)}\) for all instance \(I\)</li>
</ul>

<p>
We want to try to give some sort of upper bound to the approximation ratio. This way we can have some sort of guarantee of the approximation.
</p>

<p>
We say that the algorithm is a $&alpha;$-approximation algorithm if \(\text{approximation ratio}\le \alpha\) for any instance \(I\).
</p>
</div>
<div id="outline-container-org214b5d1" class="outline-3">
<h3 id="org214b5d1"><span class="section-number-3">13.1.</span> Minimum vertex cover approximation algorithm</h3>
<div class="outline-text-3" id="text-13-1">
<p>
A vertex cover (sometimes node cover) of a graph is a set of vertices that includes at least one endpoint of every edge of the graph. We want to find a vertex cover with the least amount of vertices.
</p>

<p>
We can use the following approximation algorithm <code>Approx-VS</code>:
</p>
<ul class="org-ul">
<li>Given the graph G, find a maximal matching M in G and let \(V_M\) be the set of saturated vertices regards M.</li>
<li>The approximation algorithm returns all vertices in \(V_M\) as a vertex cover</li>
<li>A maximal matching can be found in polynomial time.</li>
</ul>

<p>
To analyze the performance of this algorithm we need to do two things:
</p>
<ol class="org-ol">
<li><b>Feasibility:</b> show that this algorithm does provide a valid vertex cover</li>
<li><b>Approximation ratio of Approx-VC:</b> show that the size of the vertex cover returned by <code>Approx-VC</code> is not too much larger than the optimal vertex cover size in any given graph.</li>
</ol>

<p>
Feasibility: We first show that Approx-VC returns a valid vertex cover. That is, every edge is covered by at least one vertex in the set of vertices, \(V_M\) , returned by Approx-VC. This can be proven by contradiction. Suppose, for the contrary, that there is an edge (u, v) that has both of its endpoints not chosen into VM . Then, this edge should be added to M as both u and v are not saturated, which contradicts the fact that M is a maximal matching. It proves the statement.
</p>

<p>
Approximation ratio of Approx-VC: First, we note that for any instance, the size of the set returned by Approx-VC is \(|V_M | = 2|M |\), where M is a maximal matching in the input graph. On the other hand, any feasible vertex cover must contain at least one vertex in every edge in \(M\), otherwise the edge is not covered by any vertex. Hence, the size of the optimal vertex cover is at least \(|M |\). Therefore, \(\frac{\text{Approx-VC}(G)}{OPT(G)}\le \frac{2|M|}{|M|}=2\) for any input graph G. That is, Approx-VC is a 2-approximation algorithm.
</p>
</div>
</div>
<div id="outline-container-org2a36220" class="outline-3">
<h3 id="org2a36220"><span class="section-number-3">13.2.</span> Knapsack approximation algorithm</h3>
<div class="outline-text-3" id="text-13-2">
<p>
Given a set of items \(S\), each with an integral value \(v_i\) and integral weight \(w_i\). Also give integers \(B\) and \(k\). Is there a subset of \(S\) of weight no more than \(B\) with total value at least \(k\)?
</p>

<p>
<code>Approx-Knapsack</code>: Approximation algorithm for minimum vertex cover:
</p>
<ul class="org-ul">
<li>First, we sort the items in a non-increasing order of \(\frac{v_i}{ w_i}\).</li>
<li>Next, we keep a collection \(C\) by looking at the items in the non-increasing order of \(\frac{v_i}{ w_i}\) and including item \(i\) if it does not exceed the capacity.</li>
<li>Let \(v_{max}\) be the largest value of all items that can be put into the knapsack.</li>
<li>Finally, we return the collection \(C\) if the total value of the items in \(C\) is at least \(v_{max}\). Otherwise, we return \(v_{max}\).</li>
<li>\(val\leftarrow 0\)</li>
<li>Sort the items such that \(\frac{v_1}{v_1}\ge\frac{v_2}{v_2}...\ge\frac{v_n}{v_n}\)</li>
<li>\(For(i=1,2,...,n)\)
<ul class="org-ul">
<li>\(If\ B\ge w_i, val\leftarrow val+v_i \text{ and } B\leftarrow B-w_i\)</li>
</ul></li>
<li>\(\text{Return } \max \{val, v_{max}\}\) where \(v_{max}\) is the largest item value.</li>
</ul>

<p>
I did not fully understand the proof: this is just copy pasted from lecture notes.
</p>

<p>
Feasibility: According to the algorithm, the total selected weight \(\le B\)
</p>

<p>
Approximation ratio of Approx-Knapsack:
</p>
<ul class="org-ul">
<li>First, we observe that if all items (with weight at most the capacity of the knapsack) are selected by Approx-Knapsack, the algorithm‚Äôs cost is as good as optimal.</li>
<li>Therefore, in the rest of the proof we assume that there is at least one item that is not selected by the algorithm.</li>
<li>Let the items ordered in the order \[v_1 w_1 \le v_2 w_2 \le ...\] for all 2 vertices with weight of at most B, and item k is the first item that is not in C.</li>
<li>By a greedy choice argument, we know that \(v_1 + v_2 + ... + v_k > OPT\), where OPT is the total value of the items in the optimal solution.</li>
<li>By the definition of \(v_{max}, v_1 + v_2 + ... + v_{k‚àí1} + v_{max} \ge v1 + v2 + ... + v_k > OPT\).</li>
<li>Thus, v1 + v2 + ¬∑ ¬∑ ¬∑ + vk‚àí1 ‚â• OPT 2 or vmax ‚â• OPT 2 .</li>
<li>Therefore, objective of Approx-Knapsack is max{total value of C, vmax} ‚â• max{v1 + v2 + ¬∑ ¬∑ ¬∑ + vk‚àí1, vmax} ‚â• OPT 2 .</li>
<li>That is, Approx-Knapsack is a 2-approximation algorithm.</li>
</ul>


<div id="org834a514" class="figure">
<p><img src="Approximation_Algorithms/2024-04-07_13-07-41_screenshot.png" alt="2024-04-07_13-07-41_screenshot.png" />
</p>
</div>
</div>
</div>
<div id="outline-container-orgf8419d6" class="outline-3">
<h3 id="orgf8419d6"><span class="section-number-3">13.3.</span> Improving an approximation algorithm</h3>
<div class="outline-text-3" id="text-13-3">
<p>
Improving ussualy means have a smaller approximation ratio.
</p>

<p>
Take the matching-based approximation algorithm Approx-Knapsack for the minimum vertex cover problem, the possible improvement can be:
</p>
<ul class="org-ul">
<li><b>A better analysis?</b> Perhaps we overestimate the cost of Approx-Knapsack or underestimate the optimal cost? Or perhaps the small optimal cost never correlates with a large cost of the algorithm in any instance? Unfortunately, this approach does not work, as there is indeed an instance, which is a graph with exact 8 vertices and 4 edges, that incurs a ratio of 2.</li>
<li><b>A better algorithm?</b> Or, maybe we should find a better algorithm. Perhaps we don‚Äôt always need to include both endpoints. Sadly, this does not work, either. For some instances, both endpoints of the maximal matching have to be chosen.</li>
<li><b>A better observation on the optimal solution?</b> If the problem is that we cannot escape from choosing both endpoints of the maximal matching, which at the same time is a lower bound of the cost of the optimal vertex cover. Perhaps the idea is that we should find a better way to lower-bound the optimal cost</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org796ec37" class="outline-2">
<h2 id="org796ec37"><span class="section-number-2">14.</span> String Matching</h2>
<div class="outline-text-2" id="text-14">
<p>
Gegeven string (<b>haystack</b>) zoek alle voorkomens van een patroon (<b>needle</b>)
</p>
<ul class="org-ul">
<li>Tekst \(A[0..n-1]\), patroon \(P[0..m-1]\)</li>
<li>Wil: k zodat \(A[k..k+m-1]=P[0..m-1]\)</li>
<li>Tekst is over alfabet \(\Sigma (\{0,1\},\{A,B,...,Z\},[0,255],\text{etc})\)</li>
<li>We zoeken alle voorkomens van P in A</li>

<li>Gemiddelde looptijd: gemiddelde looptijd over alle invoeren
<ul class="org-ul">
<li>(som looptijden van alle invoeren) / (aantal invoeren)</li>
<li>Slimmer: bekijk een (uniforme) kansverdeling over alle invoeren, en dus een random invoer</li>
<li>Analyseert vaak een deterministisch algoritme</li>
</ul></li>
<li>Verwacht: verwachte looptijd bij √©√©n invoer
<ul class="org-ul">
<li>Algoritme maakt gebruik van randomisatie</li>
<li>Looptijd afhankelijk van random keuzes van algoritme</li>
</ul></li>
</ul>
</div>
<div id="outline-container-orgd814cbc" class="outline-3">
<h3 id="orgd814cbc"><span class="section-number-3">14.1.</span> Kansrekening</h3>
<div class="outline-text-3" id="text-14-1">
<ul class="org-ul">
<li>Variabele X waarvan de waarde afhangt van de uitkomst van een kansexperiment
<ul class="org-ul">
<li>Waarde is een getal</li>
</ul></li>
<li>Bijvoorbeeld: Het aantal keren kop als je 10 keer een munt opgooid</li>
<li>\(P(X=k)\): kans dat \(X\) waarde \(k\) heeft</li>

<li>X een toevalsvariable, met k mogelijke uitkomsten (1..k): \(\sum^k_{i=1}P(X=i)=1\)</li>
<li>Als X en Y onafhankelijk zijn. \(P(X=a\text{ en }Y=b)=P(X=a)*P(Y=b)\)</li>
<li>\(P(X=a\text{ en }Y=b)=P(X=a)*P(Y=b | X=a)\)</li>
<li>\(E[X]=\sum_{uitkomsten\ x}P(X=k)*k\) gemiddelde waarde van toevalsvariable X.</li>
<li>Lineariteit van verwachting: \(E[X_1+..+X_n]=E[X_1]+..+E[X_n]\)</li>
</ul>

<p>
<b>Bernoulli experimenten</b>
</p>
<ul class="org-ul">
<li>Kans \(p\) of succes \((X=1)\)</li>
<li>Kans \(1-p\) of succes \((X=0)\)</li>
</ul>

<p>
<b>reeks bernoullie experimenten, Geometrische verdeling</b>
</p>
<ul class="org-ul">
<li>Het aantal benodigde experimenten X tot een succes volgt</li>
<li>\(P(X=k) =(1-p)^{k-1}p\) (\(k\) aantal experimenten)</li>
<li>\(E[X]=\frac 1 p\)</li>
</ul>

<p>
Binomiale kansverdeling
</p>
<ul class="org-ul">
<li>X = aantal successen na n Bernouilli experimenten</li>
<li>\(E[X] = np\)</li>
<li>Voorbeeld: X is aantal keren kop bij 10 keer muntwerpen: \(E[X]=5\)</li>
</ul>

<p>
Negatief binomiale kansverdeling
</p>
<ul class="org-ul">
<li>X = aantal falen tot r succesvolle Bernouilli experimenten</li>
<li>\(E[X] = (r/p)-r\)</li>
</ul>

<p>
Andere:
</p>
<ul class="org-ul">
<li>Poisson kansverdeling</li>
<li>Continue kansverdeling</li>
</ul>
</div>
</div>
<div id="outline-container-orgecaebc5" class="outline-3">
<h3 id="orgecaebc5"><span class="section-number-3">14.2.</span> Naief algoritme</h3>
<div class="outline-text-3" id="text-14-2">
<div class="org-src-container">
<pre class="src src-python">NaiveMatch(A,P)
    <span style="color: #bb99ee;">for</span> k :<span style="color: #88ccdd;">=</span> <span style="color: #eeaa77;">0</span> to n<span style="color: #88ccdd;">-</span>m<span style="color: #88ccdd;">-</span><span style="color: #eeaa77;">1</span>
    <span style="color: #bb99ee;">if</span> Checkmatch(A,k,P)
        output k
<span style="color: #bb99ee;">return</span>

CheckMatch(A,k,P)
    <span style="color: #bb99ee;">for</span> i :<span style="color: #88ccdd;">=</span> <span style="color: #eeaa77;">0</span> to m<span style="color: #88ccdd;">-</span><span style="color: #eeaa77;">1</span>
        <span style="color: #bb99ee;">if</span> A[k<span style="color: #88ccdd;">+</span>i] &#8800; P[i]
            <span style="color: #bb99ee;">return</span> false
<span style="color: #bb99ee;">return</span> true
</pre>
</div>

<p>
Worst case complexity of \(O(mn)\), best case \(O(n)\)
</p>

<p>
Gemiddelde looptijd:
</p>
<ul class="org-ul">
<li>Invoer is random string</li>
<li>Kans dat de loop van CheckMatch stopt op een bepaalde iteratie is kans \(\frac {25} {26}\)</li>
<li>Verwacht \(\frac {26} {25}\)</li>
<li>Dus \(O(1)\) verwachte vergelijkingen, dus looptijd \(O(n)\)</li>
</ul>

<p>
Dit algoritme is traag want het gebruikt de informatie van een mismatch niet
</p>
</div>
</div>
<div id="outline-container-org6c798a4" class="outline-3">
<h3 id="org6c798a4"><span class="section-number-3">14.3.</span> Rabin-Karp</h3>
<div class="outline-text-3" id="text-14-3">
<p>
Idee: sla strings op als getallen in base \(|\Sigma |\)
</p>

<p>
Bijvoorbeeld: zoek orit in algoritme
</p>
<ul class="org-ul">
<li>\(orit = 15 * 26^3 + 18 * 26^2 + 9 * 26^1 + 20 = 15 / 26 + 18 / 26 + 9 / 26 + 20 = 276062\)</li>
<li>\(algo = 1 * 26 + 12 * 26 + 7 * 26 + 15 = 25885\)</li>
<li>\(lgor = 12 * 26 + 7 * 26 + 15 * 26 + 18 = 216052\)</li>
<li>\(gori= 7 * 26 + 15 * 26 + 18 * 26 + 9 = 133649\)</li>
<li>\(orit= 15 * 26 + 18 * 26 + 9 * 26 + 20 = 276062\)</li>
</ul>

<p>
Snel herberekenen kan in \(O(1)\) door te schuiven.
</p>
<ul class="org-ul">
<li>Algo: \(H(0)=1*26^3+12*26^2+7*26^1+15*26^0\)</li>
<li>Igor: \(H(1)=12*26^3+7*26^2+15*26^1+18*26^0\)</li>
</ul>

<p>
Algemeen: \(H(K+1)=A[k+m+1]+|\Sigma |*(H(k)-A[k]*|\Sigma|^{m-1})\)
</p>
<ul class="org-ul">
<li>\(H(K+1)=A[k+m+1]+H(k)*|\Sigma |-A[k]*|\Sigma|^{m}\)</li>
</ul>

<div class="org-src-container">
<pre class="src src-python">RK2(A,P)
    ph :<span style="color: #88ccdd;">=</span> String2Int(P)
    sh :<span style="color: #88ccdd;">=</span> String2Int(A[<span style="color: #eeaa77;">0</span>&#8230;m<span style="color: #88ccdd;">-</span><span style="color: #eeaa77;">1</span>])
    <span style="color: #bb99ee;">for</span> k :<span style="color: #88ccdd;">=</span> <span style="color: #eeaa77;">0</span> to n<span style="color: #88ccdd;">-</span>m<span style="color: #88ccdd;">-</span><span style="color: #eeaa77;">1</span>
        <span style="color: #bb99ee;">if</span> (ph <span style="color: #88ccdd;">==</span> sh)
            output k
    sh :<span style="color: #88ccdd;">=</span> A[k<span style="color: #88ccdd;">+</span>m<span style="color: #88ccdd;">+</span><span style="color: #eeaa77;">1</span>] <span style="color: #88ccdd;">+</span> sh &#215; &#931; &#8211; A[k] &#215; &#931;<span style="color: #88ccdd;">^</span>m
<span style="color: #bb99ee;">return</span>
</pre>
</div>
<p>
Op getallen met \(O(m\log |\sigma|)\) bits
</p>
<ul class="org-ul">
<li>Hash kan tot \(|\Sigma |^m\) groot zijn</li>
<li>\(\log |\Sigma |^m = O(m\log |\sigma|)\)</li>
<li>Dit is te groot om \(O(1)\) te zijn</li>

<li>ùëÇ(1)-bits woorden: 32/64/128-bits computers
<ul class="org-ul">
<li>Tijd van complexe arithmetische operaties?</li>
</ul></li>
<li>Veel gebruikt: ùëÇ(log ùëõ)-bits woorden (Word- RAM model)
<ul class="org-ul">
<li>We kunnen operaties in O(1) tijd doen op getallen met ùëÇ(log ùëõ) bits</li>
<li>|Œ£| ‚â§ n + m ‚â§ 2n, dus O(log n)-bits nodig per letter</li>
<li>O(m log |Œ£|) bits kan nog steeds te veel zijn</li>
</ul></li>
<li>Kunnen we toch binnen de grenzen (van Word-RAM) blijven?</li>
</ul>

<p>
Gebruik getallen modulo q:
</p>

<p>
Als twee woorden gelijk zijn dat is de mod gelijk, maar andersom geld de relatie niet.
</p>
<ul class="org-ul">
<li>Als twee hashes gelijk zijn moet je dus nog handmatig de string controleren.</li>
</ul>

<div class="org-src-container">
<pre class="src src-python">RK4(A,P)
    ph :<span style="color: #88ccdd;">=</span> String2Int(P) <span style="color: #88ccdd;">%</span> q
    sh :<span style="color: #88ccdd;">=</span> String2Int(A[<span style="color: #eeaa77;">0</span>&#8230;m<span style="color: #88ccdd;">-</span><span style="color: #eeaa77;">1</span>]) <span style="color: #88ccdd;">%</span> q
    <span style="color: #bb99ee;">for</span> k :<span style="color: #88ccdd;">=</span> <span style="color: #eeaa77;">0</span> to n<span style="color: #88ccdd;">-</span>m<span style="color: #88ccdd;">-</span><span style="color: #eeaa77;">1</span>
        <span style="color: #bb99ee;">if</span> (ph <span style="color: #88ccdd;">==</span> sh) <span style="color: #bb99ee;">and</span> CheckMatch(A,k,P)
            output k
    sh :<span style="color: #88ccdd;">=</span> A[k<span style="color: #88ccdd;">+</span>m<span style="color: #88ccdd;">+</span><span style="color: #eeaa77;">1</span>] <span style="color: #88ccdd;">+</span> sh &#215; &#931; &#8211; A[k] &#215; &#931;<span style="color: #88ccdd;">^</span>m <span style="color: #88ccdd;">%</span> q
<span style="color: #bb99ee;">return</span>
</pre>
</div>

<ul class="org-ul">
<li>Nu looptijd \(O(n)\) voor checken van de hash</li>
<li>\(O(m)\) per gevonden substring</li>
<li>\(O(m)\) per spurious hit</li>
</ul>
</div>
</div>
<div id="outline-container-org3f290b9" class="outline-3">
<h3 id="org3f290b9"><span class="section-number-3">14.4.</span> Eindige automaat</h3>
<div class="outline-text-3" id="text-14-4">
<ul class="org-ul">
<li>Eindige Automaat/Finite Automaton</li>
<li>\(O(n)\) tijd met \(O(m|\Sigma |)\) preprocessing</li>
<li>Geen kosten voor hits</li>
<li>Gebruikt informatie van eerdere mismatch</li>
<li>Ieder symbool 1 keer bekeken</li>
</ul>

<p>
Toestanden: Q
</p>

<p>
Overgangen: \(\delta : Q\time \Sigma \rightarrow Q\)
</p>


<div id="org1491c2b" class="figure">
<p><img src="String_Matching/2024-04-02_14-55-12_screenshot.png" alt="2024-04-02_14-55-12_screenshot.png" />
</p>
</div>

<p>
We gebruiken getallen voor toestanden, other laten we impliciet:
<img src="String_Matching/2024-04-02_14-54-38_screenshot.png" alt="2024-04-02_14-54-38_screenshot.png" />
</p>

<div class="org-src-container">
<pre class="src src-python">DFA<span style="color: #88ccdd;">-</span>Match(A,P)
    s :<span style="color: #88ccdd;">=</span> <span style="color: #eeaa77;">0</span>
    &#948; :<span style="color: #88ccdd;">=</span> overgangsfunctie van P
    <span style="color: #bb99ee;">for</span> i :<span style="color: #88ccdd;">=</span> <span style="color: #eeaa77;">0</span> to n<span style="color: #88ccdd;">-</span><span style="color: #eeaa77;">1</span>
        s :<span style="color: #88ccdd;">=</span> &#948;(s, A[i])
        <span style="color: #bb99ee;">if</span> s <span style="color: #88ccdd;">=</span> m
            output i<span style="color: #88ccdd;">-</span>m<span style="color: #88ccdd;">+</span><span style="color: #eeaa77;">1</span>
    <span style="color: #bb99ee;">return</span>
</pre>
</div>

<p>
Overgangsfunctie:
</p>
<ul class="org-ul">
<li>\(\delta (i,x) =\) wat is de volgende toestand als we x lezen en nu in toestand i zijn?</li>
<li>\(i+1\) als \(x=P[i]\)</li>
<li>de grootste \(j\le i\) zodat \(P[i-j..i-1]=P[0..j-2]\) en \(P[j-1]=x\)</li>
<li>start-toestand indien zo‚Äôn \(j\) niet bestaat</li>
<li>Naief: \(O(m^3|\Sigma |)\), kan in: \(O(m|\Sigma |)\)</li>
</ul>

<p>
Eindige automaat is \(O(n)\) tijd, met \(O(m|\Sigma |)\)
</p>

<p>
<i>Na slide 60 en knuth morris hoeven we niet te weten</i>
</p>
</div>
</div>
</div>
<div id="outline-container-org8cb2203" class="outline-2">
<h2 id="org8cb2203"><span class="section-number-2">15.</span> Gerandomiseerde algoritmes</h2>
<div class="outline-text-2" id="text-15">
<p>
Gebruiken getallen uit toevalsgeneratoren
</p>

<p>
De toevalsgetallen sturen twee dingen:
</p>
<ul class="org-ul">
<li>hoe lang het algoritme zoekt</li>
<li>in welk deel van de oplossingsruimte het algoritme zoekt</li>
</ul>

<p>
Twee dingen zijn belangrijk bij randomisatie:
</p>
<ol class="org-ol">
<li>Wat is de kans dat het algoritme een (in)correct antwoord geeft?</li>
<li>Wat is de (verwachte) looptijd van het algoritme?</li>
</ol>

<p>
Er zijn twee types gerandomiseerde algoritmes:
</p>

<p>
<b>Las Vegas algoritme:</b>
</p>
<ul class="org-ul">
<li>Geeft altijd een correct ja/nee antwoord of oplossing</li>
<li>Verwachte looptijd is eindig/beperkt</li>
<li>Intu√Øtie: we gokken met hoeveel rekentijd we gebruiken, maar niet met het antwoord</li>
</ul>

<p>
<b>Monte Carlo algoritme:</b>
</p>
<ul class="org-ul">
<li>Geeft niet altijd een correct antwoord
<ul class="org-ul">
<li>Eenzijdige fout of tweezijdige fout</li>
<li>Wel grote kans op goed antwoord</li>
</ul></li>
<li>Worst-case looptijd is eindig/beperkt</li>
<li>Intu√Øtie: we gokken met het antwoord, maar niet met hoeveel looptijd we nodig hebben</li>
</ul>

<p>
Ieder Las Vegas algoritme kan een Monte Carlo algoritme worden
</p>
<ul class="org-ul">
<li>Be√´indig het LV algoritme na zekere tijd en geef eventueel een willekeurig antwoord terug</li>
<li>M.b.v. kansrekening bepaal je vervolgens de kans op het goede antwoord</li>
</ul>

<p>
Ieder Monte Carlo algoritme kan een Las Vegas algoritme worden, mits je effici√´nt kunt controleren of een antwoord correct is
</p>
<ul class="org-ul">
<li>Draai het Monte Carlo algoritme net zo lang totdat de oplossing correct is</li>
<li>M.b.v. kansrekening bepaal je vervolgens de verwachte looptijd</li>
</ul>

<p>
Toevalsvariable \(X\), \(P(X=k)\): kans dat \(X\) waarde \(k\) heeft
</p>

<p>
\(E[X] =\) gemiddelde waarde van toevalsvariabele \(X\), gewogen door kansen
</p>

<p>
Bekijk een reeks onafhankelijke Bernouilli experimenten (kans p op succes)
</p>
<ul class="org-ul">
<li>Het aantal benodigde experimenten X tot een succes volgt een geometrische kansverdelinlg</li>
<li>\(P(X=k)=(1-p)^{k-1}p\)</li>
<li>\(E[X]=\frac 1 p\)</li>
</ul>
</div>
<div id="outline-container-org9643cb6" class="outline-3">
<h3 id="org9643cb6"><span class="section-number-3">15.1.</span> <span class="todo TODO">TODO</span> Minimum cut probleem met gerandomiseerd algoritme</h3>
<div class="outline-text-3" id="text-15-1">
<p>
kijk ff in werkcollege hoe belangrijk dit is
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Martijn Voordouw</p>
<p class="date">Created: 2024-06-30 zo 11:56</p>
</div>
</body>
</html>
